<!DOCTYPE html><html><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content=" id=&quot;Learning-Scrapy-Book&quot;&gt;&lt;a href=&quot;#Learning-Scrapy-Book&quot; class=&quot;headerlink&quot; title=&quot;Learning Scrapy Book&quot;&gt;&lt;/a&gt;Learning Scrapy Book&lt;/h1&gt;&lt;p&gt;This book covers the long awaited Scrapy v 1.0 that empowers you to extract useful data from virtually any source with very little effort. It starts off by explaining the fundamentals of Scrapy framework, followed by a thorough description of how to extract data from any source, clean it up, shape it as per your requirement using Python and 3rd party APIs. Next you will be familiarised with the process of storing the scrapped data in databases as well as search engines and performing real time analytics on them with Spark Streaming. By the end of this book, you will perfect the art of scraping data for your applications with ease."><link rel="stylesheet" type="text/css" href="/css/normalize.css"><link rel="stylesheet" type="text/css" href="/css/highlight.css"><link rel="stylesheet" type="text/css" href="/css/noise.css"><title>README | 凉薄的自动书记人偶</title><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><meta name="generator" content="Hexo 5.4.0"></head><body><article class="wrapper"><div class="post-main"><div class="nav"><nav class="container"><a class="sidebar-nav-item active" href="/">Home</a><a class="sidebar-nav-item" href="/archives">Tags</a><a class="sidebar-nav-item" href="/About">About</a></nav><div class="container post-meta"><div class="post-tags"><a class="post-tag-link" href="/tags/Python-Crawler/" rel="tag">Python Crawler</a></div><div class="post-time">2017-09-14</div></div></div><div class="container post-header"><h1>README</h1></div><div class="container post-toc"><details class="toc"><summary class="toc-accordion">Table of Contents</summary><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Learning-Scrapy-Book"><span class="toc-number">1.</span> <span class="toc-text">Learning Scrapy Book</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#What-you-will-learn"><span class="toc-number">1.1.</span> <span class="toc-text">What you will learn</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Tutorials"><span class="toc-number">1.2.</span> <span class="toc-text">Tutorials</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#To-use-Docker-directly-without-installing-Vagrant"><span class="toc-number">1.3.</span> <span class="toc-text">To use Docker directly without installing Vagrant</span></a></li></ol></li></ol></details></div><div class="container post-content"><h1 id="Learning-Scrapy-Book"><a href="#Learning-Scrapy-Book" class="headerlink" title="Learning Scrapy Book"></a>Learning Scrapy Book</h1><p>This book covers the long awaited Scrapy v 1.0 that empowers you to extract useful data from virtually any source with very little effort. It starts off by explaining the fundamentals of Scrapy framework, followed by a thorough description of how to extract data from any source, clean it up, shape it as per your requirement using Python and 3rd party APIs. Next you will be familiarised with the process of storing the scrapped data in databases as well as search engines and performing real time analytics on them with Spark Streaming. By the end of this book, you will perfect the art of scraping data for your applications with ease.</p>
<p>This book is now available on <a target="_blank" rel="noopener" href="http://amzn.to/1PeQ5O0">Amazon</a> and <a target="_blank" rel="noopener" href="https://www.packtpub.com/big-data-and-business-intelligence/learning-scrapy">Packt</a>.</p>
<h2 id="What-you-will-learn"><a href="#What-you-will-learn" class="headerlink" title="What you will learn"></a>What you will learn</h2><ul>
<li>Understand HTML pages and write XPath to extract the data you need</li>
<li>Write Scrapy spiders with simple Python and do web crawls</li>
<li>Push your data into any database, search engine or analytics system</li>
<li>Configure your spider to download files, images and use proxies</li>
<li>Create efficient pipelines that shape data in precisely the form you want</li>
<li>Use Twisted Asynchronous API to process hundreds of items concurrently</li>
<li>Make your crawler super-fast by learning how to tune Scrapy’s performance</li>
<li>Perform large scale distributed crawls with scrapyd and scrapinghub</li>
</ul>
<h2 id="Tutorials"><a href="#Tutorials" class="headerlink" title="Tutorials"></a>Tutorials</h2><ul>
<li>How to Setup Software and Run Examples On A Windows Machine</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=r84-dsIRFI8"><img src="/images/b740a557-0c016008-1555-11e7-86e3-c736e953a199.PNG" alt="image"></a></p>
<ul>
<li>Chapter 4 - Create Appery.io mobile application - Updated process</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=FEbPyQJc3NE"><img src="/images/b9e93d99-e6c99072-1503-11e7-9d45-7eed9c13c7b6.png" alt="image"></a></p>
<ul>
<li>Chapter 3 &amp; 9 on a 32-bit VM (for computers limited memory/processing power)</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=w9ditoIQ7sU"><img src="/images/25cc97ad-26a8eae6-14e9-11e7-9244-d5117954ccea.png" alt="image"></a></p>
<h2 id="To-use-Docker-directly-without-installing-Vagrant"><a href="#To-use-Docker-directly-without-installing-Vagrant" class="headerlink" title="To use Docker directly without installing Vagrant"></a>To use Docker directly without installing Vagrant</h2><p>A <code>docker-compose.yml</code> file is included, mainly for those who already have Docker installed. For completeness, here are the links to go about installing Docker.</p>
<ul>
<li>For OS X El Capitan 10.11 and later, get <a target="_blank" rel="noopener" href="https://docs.docker.com/docker-for-mac/">Docker for Mac</a>.</li>
<li>For earlier OS X, get <a target="_blank" rel="noopener" href="https://docs.docker.com/toolbox/toolbox_install_mac/">Docker Toolbox for Mac</a>.</li>
<li>For Windows 10 Pro, with Enterprise and Education (1511 November update, Build 10586 or later), get <a target="_blank" rel="noopener" href="https://docs.docker.com/docker-for-windows/">Docker for Windows</a>.</li>
<li>For Windows 7, 8.1 or other 10, get <a target="_blank" rel="noopener" href="https://docs.docker.com/toolbox/toolbox_install_windows/">Docker Toolbox for Windows</a>.</li>
<li>For Ubuntu and other Linux distributions, install<br><a target="_blank" rel="noopener" href="https://docs.docker.com/engine/installation/linux/ubuntu/">docker</a> and<br><a target="_blank" rel="noopener" href="https://docs.docker.com/compose/install/">docker-compose</a>.<br>To <a target="_blank" rel="noopener" href="https://docs.docker.com/engine/installation/linux/linux-postinstall/">avoid having to use sudo when you use the docker command</a>,<br>create a Unix group called docker and add users to it:<ol>
<li><code>sudo groupadd docker</code></li>
<li><code>sudo usermod -aG docker $USER</code></li>
</ol>
</li>
</ul>
<p>Once you have Docker installed and started, change to the project directory and run:</p>
<ol>
<li><code>docker-compose pull</code> - To check for updated images</li>
<li><code>docker-compose up</code> - Will scroll log messages as various containers (virtual machines) start up. To stop the containers, Ctrl-C in this window, or enter <code>docker-compose down</code> in another shell window.</li>
</ol>
<p><code>docker system prune</code> will delete the system-wide Docker images, containers, and volumes that are not in use when you want to recover space.</p>
<p>See also <a target="_blank" rel="noopener" href="http://scrapybook.com/">the official website</a></p>
</div></div></article><link rel="stylesheet" type="text/css" href="/css/font.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.css"><script src="//cdn.bootcss.com/jquery/2.0.3/jquery.min.js"></script><script src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js"></script><script>$(document).ready(function() {
  $(".fancybox").fancybox();
});
</script></body></html>