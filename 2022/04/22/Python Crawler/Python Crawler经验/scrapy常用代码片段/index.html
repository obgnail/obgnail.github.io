<!DOCTYPE html><html><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content=" id=&quot;序&quot;&gt;&lt;a href=&quot;#序&quot; class=&quot;headerlink&quot; title=&quot;序&quot;&gt;&lt;/a&gt;序&lt;/h2&gt;&lt;p&gt;扒拉了一下老电脑，把 N 年前的笔记搬过来了。这个是初学 scrapy 的笔记，留作纪念。"><link rel="stylesheet" type="text/css" href="/css/normalize.css"><link rel="stylesheet" type="text/css" href="/css/highlight.css"><link rel="stylesheet" type="text/css" href="/css/noise.css"><title>scrapy常用代码片段 | 凉薄的自动书记人偶</title><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><meta name="generator" content="Hexo 5.4.0"></head><body><article class="wrapper"><div class="post-main"><div class="nav"><nav class="container"><a class="sidebar-nav-item active" href="/">Home</a><a class="sidebar-nav-item" href="/archives">Tags</a><a class="sidebar-nav-item" href="/About">About</a></nav><div class="container post-meta"><div class="post-tags"><a class="post-tag-link" href="/tags/Python-Crawler/" rel="tag">Python Crawler</a></div><div class="post-time">2022-04-22</div></div></div><div class="container post-header"><h1>scrapy常用代码片段</h1></div><div class="container post-toc"><details class="toc"><summary class="toc-accordion">Table of Contents</summary><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BA%8F"><span class="toc-number">1.</span> <span class="toc-text">序</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Middleware"><span class="toc-number">2.</span> <span class="toc-text">Middleware</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#start-requests"><span class="toc-number">3.</span> <span class="toc-text">start_requests</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ImagePipeline"><span class="toc-number">4.</span> <span class="toc-text">ImagePipeline</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#JsonWriterPipeline"><span class="toc-number">5.</span> <span class="toc-text">JsonWriterPipeline</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MongoPipeline"><span class="toc-number">6.</span> <span class="toc-text">MongoPipeline</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MysqlPipeline"><span class="toc-number">7.</span> <span class="toc-text">MysqlPipeline</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ScreenshotPipeline"><span class="toc-number">8.</span> <span class="toc-text">ScreenshotPipeline</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DuplicatesPipeline%EF%BC%9A%E9%A1%B9%E7%9B%AE%E5%8E%BB%E9%87%8D"><span class="toc-number">9.</span> <span class="toc-text">DuplicatesPipeline：项目去重</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RandomUserAgentMiddleware"><span class="toc-number">10.</span> <span class="toc-text">RandomUserAgentMiddleware</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ProxyMiddleware"><span class="toc-number">11.</span> <span class="toc-text">ProxyMiddleware</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ChromeDownloaderMiddleware%EF%BC%9A%E5%AF%B9%E6%8E%A5selenium"><span class="toc-number">12.</span> <span class="toc-text">ChromeDownloaderMiddleware：对接selenium</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#TaobaoSpider"><span class="toc-number">13.</span> <span class="toc-text">TaobaoSpider</span></a></li></ol></details></div><div class="container post-content"><h2 id="序"><a href="#序" class="headerlink" title="序"></a>序</h2><p>扒拉了一下老电脑，把 N 年前的笔记搬过来了。这个是初学 scrapy 的笔记，留作纪念。</p>
<h2 id="Middleware"><a href="#Middleware" class="headerlink" title="Middleware"></a>Middleware</h2><p><img src="/images/scrapy%E4%B8%AD%E9%97%B4%E4%BB%B6.png" alt="scrapy中间件"></p>
<h2 id="start-requests"><a href="#start-requests" class="headerlink" title="start_requests"></a>start_requests</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">start_request</span>(<span class="params">self</span>):</span></span><br><span class="line">  <span class="keyword">for</span> url <span class="keyword">in</span> self.start_urls:</span><br><span class="line">    <span class="keyword">yield</span> self.make_requests_from_url(url)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_requests_from_url</span>(<span class="params">self, url</span>):</span></span><br><span class="line">  <span class="keyword">return</span> Request(url, dont_filter=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>



<h2 id="ImagePipeline"><a href="#ImagePipeline" class="headerlink" title="ImagePipeline"></a>ImagePipeline</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ImagesPipeline</span>(<span class="params">FilesPipeline</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Abstract pipeline that implement the image thumbnail generation logic</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    MEDIA_NAME = <span class="string">&#x27;image&#x27;</span></span><br><span class="line">    MIN_WIDTH = <span class="number">0</span></span><br><span class="line">    MIN_HEIGHT = <span class="number">0</span></span><br><span class="line">    THUMBS = &#123;&#125;</span><br><span class="line">    DEFAULT_IMAGES_URLS_FIELD = <span class="string">&#x27;image_urls&#x27;</span></span><br><span class="line">    DEFAULT_IMAGES_RESULT_FIELD = <span class="string">&#x27;images&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_settings</span>(<span class="params">cls, settings</span>):</span></span><br><span class="line">        cls.MIN_WIDTH = settings.getint(<span class="string">&#x27;IMAGES_MIN_WIDTH&#x27;</span>, <span class="number">0</span>)</span><br><span class="line">        cls.MIN_HEIGHT = settings.getint(<span class="string">&#x27;IMAGES_MIN_HEIGHT&#x27;</span>, <span class="number">0</span>)</span><br><span class="line">        cls.EXPIRES = settings.getint(<span class="string">&#x27;IMAGES_EXPIRES&#x27;</span>, <span class="number">90</span>)</span><br><span class="line">        cls.THUMBS = settings.get(<span class="string">&#x27;IMAGES_THUMBS&#x27;</span>, &#123;&#125;)</span><br><span class="line">        s3store = cls.STORE_SCHEMES[<span class="string">&#x27;s3&#x27;</span>]</span><br><span class="line">        s3store.AWS_ACCESS_KEY_ID = settings[<span class="string">&#x27;AWS_ACCESS_KEY_ID&#x27;</span>]</span><br><span class="line">        s3store.AWS_SECRET_ACCESS_KEY = settings[<span class="string">&#x27;AWS_SECRET_ACCESS_KEY&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        cls.IMAGES_URLS_FIELD = settings.get(<span class="string">&#x27;IMAGES_URLS_FIELD&#x27;</span>, cls.DEFAULT_IMAGES_URLS_FIELD)</span><br><span class="line">        cls.IMAGES_RESULT_FIELD = settings.get(<span class="string">&#x27;IMAGES_RESULT_FIELD&#x27;</span>, cls.DEFAULT_IMAGES_RESULT_FIELD)</span><br><span class="line">        store_uri = settings[<span class="string">&#x27;IMAGES_STORE&#x27;</span>]</span><br><span class="line">        <span class="keyword">return</span> cls(store_uri)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">file_downloaded</span>(<span class="params">self, response, request, info</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.image_downloaded(response, request, info)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">image_downloaded</span>(<span class="params">self, response, request, info</span>):</span></span><br><span class="line">        checksum = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">for</span> path, image, buf <span class="keyword">in</span> self.get_images(response, request, info):</span><br><span class="line">            <span class="keyword">if</span> checksum <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                buf.seek(<span class="number">0</span>)</span><br><span class="line">                checksum = md5sum(buf)</span><br><span class="line">            width, height = image.size</span><br><span class="line">            self.store.persist_file(</span><br><span class="line">                path, buf, info,</span><br><span class="line">                meta=&#123;<span class="string">&#x27;width&#x27;</span>: width, <span class="string">&#x27;height&#x27;</span>: height&#125;,</span><br><span class="line">                headers=&#123;<span class="string">&#x27;Content-Type&#x27;</span>: <span class="string">&#x27;image/jpeg&#x27;</span>&#125;)</span><br><span class="line">        <span class="keyword">return</span> checksum</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_images</span>(<span class="params">self, response, request, info</span>):</span></span><br><span class="line">        path = self.file_path(request, response=response, info=info)</span><br><span class="line">        orig_image = Image.<span class="built_in">open</span>(StringIO(response.body))</span><br><span class="line"></span><br><span class="line">        width, height = orig_image.size</span><br><span class="line">        <span class="keyword">if</span> width &lt; self.MIN_WIDTH <span class="keyword">or</span> height &lt; self.MIN_HEIGHT:</span><br><span class="line">            <span class="keyword">raise</span> ImageException(<span class="string">&quot;Image too small (%dx%d &lt; %dx%d)&quot;</span> %</span><br><span class="line">                                 (width, height, self.MIN_WIDTH, self.MIN_HEIGHT))</span><br><span class="line"></span><br><span class="line">        image, buf = self.convert_image(orig_image)</span><br><span class="line">        <span class="keyword">yield</span> path, image, buf</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> thumb_id, size <span class="keyword">in</span> self.THUMBS.iteritems():</span><br><span class="line">            thumb_path = self.thumb_path(request, thumb_id, response=response, info=info)</span><br><span class="line">            thumb_image, thumb_buf = self.convert_image(image, size)</span><br><span class="line">            <span class="keyword">yield</span> thumb_path, thumb_image, thumb_buf</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">convert_image</span>(<span class="params">self, image, size=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="keyword">if</span> image.<span class="built_in">format</span> == <span class="string">&#x27;PNG&#x27;</span> <span class="keyword">and</span> image.mode == <span class="string">&#x27;RGBA&#x27;</span>:</span><br><span class="line">            background = Image.new(<span class="string">&#x27;RGBA&#x27;</span>, image.size, (<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>))</span><br><span class="line">            background.paste(image, image)</span><br><span class="line">            image = background.convert(<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line">        <span class="keyword">elif</span> image.mode != <span class="string">&#x27;RGB&#x27;</span>:</span><br><span class="line">            image = image.convert(<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> size:</span><br><span class="line">            image = image.copy()</span><br><span class="line">            image.thumbnail(size, Image.ANTIALIAS)</span><br><span class="line"></span><br><span class="line">        buf = StringIO()</span><br><span class="line">        image.save(buf, <span class="string">&#x27;JPEG&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> image, buf</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_media_requests</span>(<span class="params">self, item, info</span>):</span></span><br><span class="line">        <span class="keyword">return</span> [Request(x) <span class="keyword">for</span> x <span class="keyword">in</span> item.get(self.IMAGES_URLS_FIELD, [])]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">item_completed</span>(<span class="params">self, results, item, info</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.IMAGES_RESULT_FIELD <span class="keyword">in</span> item.fields:</span><br><span class="line">            item[self.IMAGES_RESULT_FIELD] = [x <span class="keyword">for</span> ok, x <span class="keyword">in</span> results <span class="keyword">if</span> ok]</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">file_path</span>(<span class="params">self, request, response=<span class="literal">None</span>, info=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="comment">## start of deprecation warning block (can be removed in the future)</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">_warn</span>():</span></span><br><span class="line">            <span class="keyword">from</span> scrapy.exceptions <span class="keyword">import</span> ScrapyDeprecationWarning</span><br><span class="line">            <span class="keyword">import</span> warnings</span><br><span class="line">            warnings.warn(<span class="string">&#x27;ImagesPipeline.image_key(url) and file_key(url) methods are deprecated, &#x27;</span></span><br><span class="line">                          <span class="string">&#x27;please use file_path(request, response=None, info=None) instead&#x27;</span>,</span><br><span class="line">                          category=ScrapyDeprecationWarning, stacklevel=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># check if called from image_key or file_key with url as first argument</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(request, Request):</span><br><span class="line">            _warn()</span><br><span class="line">            url = request</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            url = request.url</span><br><span class="line"></span><br><span class="line">        <span class="comment"># detect if file_key() or image_key() methods have been overridden</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">hasattr</span>(self.file_key, <span class="string">&#x27;_base&#x27;</span>):</span><br><span class="line">            _warn()</span><br><span class="line">            <span class="keyword">return</span> self.file_key(url)</span><br><span class="line">        <span class="keyword">elif</span> <span class="keyword">not</span> <span class="built_in">hasattr</span>(self.image_key, <span class="string">&#x27;_base&#x27;</span>):</span><br><span class="line">            _warn()</span><br><span class="line">            <span class="keyword">return</span> self.image_key(url)</span><br><span class="line">        <span class="comment">## end of deprecation warning block</span></span><br><span class="line"></span><br><span class="line">        image_guid = hashlib.sha1(url).hexdigest()  <span class="comment"># change to request.url after deprecation</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;full/%s.jpg&#x27;</span> % (image_guid)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">thumb_path</span>(<span class="params">self, request, thumb_id, response=<span class="literal">None</span>, info=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="comment">## start of deprecation warning block (can be removed in the future)</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">_warn</span>():</span></span><br><span class="line">            <span class="keyword">from</span> scrapy.exceptions <span class="keyword">import</span> ScrapyDeprecationWarning</span><br><span class="line">            <span class="keyword">import</span> warnings</span><br><span class="line">            warnings.warn(<span class="string">&#x27;ImagesPipeline.thumb_key(url) method is deprecated, please use &#x27;</span></span><br><span class="line">                          <span class="string">&#x27;thumb_path(request, thumb_id, response=None, info=None) instead&#x27;</span>,</span><br><span class="line">                          category=ScrapyDeprecationWarning, stacklevel=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># check if called from thumb_key with url as first argument</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(request, Request):</span><br><span class="line">            _warn()</span><br><span class="line">            url = request</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            url = request.url</span><br><span class="line"></span><br><span class="line">        <span class="comment"># detect if thumb_key() method has been overridden</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">hasattr</span>(self.thumb_key, <span class="string">&#x27;_base&#x27;</span>):</span><br><span class="line">            _warn()</span><br><span class="line">            <span class="keyword">return</span> self.thumb_key(url, thumb_id)</span><br><span class="line">        <span class="comment">## end of deprecation warning block</span></span><br><span class="line"></span><br><span class="line">        thumb_guid = hashlib.sha1(url).hexdigest()  <span class="comment"># change to request.url after deprecation</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;thumbs/%s/%s.jpg&#x27;</span> % (thumb_id, thumb_guid)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># deprecated</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">file_key</span>(<span class="params">self, url</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.image_key(url)</span><br><span class="line">    file_key._base = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># deprecated</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">image_key</span>(<span class="params">self, url</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.file_path(url)</span><br><span class="line">    image_key._base = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># deprecated</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">thumb_key</span>(<span class="params">self, url, thumb_id</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.thumb_path(url, thumb_id)</span><br><span class="line">    thumb_key._base = <span class="literal">True</span></span><br></pre></td></tr></table></figure>



<h2 id="JsonWriterPipeline"><a href="#JsonWriterPipeline" class="headerlink" title="JsonWriterPipeline"></a>JsonWriterPipeline</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将项目写入JSON文件</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JsonWriterPipeline</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        self.file = <span class="built_in">open</span>(<span class="string">&#x27;items.jl&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        self.file.close()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self, item, spider</span>):</span></span><br><span class="line">        line = json.dumps(<span class="built_in">dict</span>(item)) + <span class="string">&quot;\n&quot;</span></span><br><span class="line">        self.file.write(line)</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>



<h2 id="MongoPipeline"><a href="#MongoPipeline" class="headerlink" title="MongoPipeline"></a>MongoPipeline</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将项目写入MongoDB</span></span><br><span class="line"><span class="comment"># MongoDB地址和数据库名称在Scrapy设置中指定; MongoDB集合以item类命名。</span></span><br><span class="line"><span class="comment"># 这个例子的要点是显示如何使用from_crawler()方法和如何正确清理资源</span></span><br><span class="line"><span class="keyword">import</span> pymongo</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MongoPipeline</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    collection_name = <span class="string">&#x27;scrapy_items&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, mongo_uri, mongo_db</span>):</span></span><br><span class="line">        self.mongo_uri = mongo_uri</span><br><span class="line">        self.mongo_db = mongo_db</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span>(<span class="params">cls, crawler</span>):</span></span><br><span class="line">        <span class="keyword">return</span> cls(</span><br><span class="line">            mongo_uri=crawler.settings.get(<span class="string">&#x27;MONGO_URI&#x27;</span>),</span><br><span class="line">            mongo_db=crawler.settings.get(<span class="string">&#x27;MONGO_DATABASE&#x27;</span>, <span class="string">&#x27;items&#x27;</span>)</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        self.client = pymongo.MongoClient(self.mongo_uri)</span><br><span class="line">        self.db = self.client[self.mongo_db]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        self.client.close()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self, item, spider</span>):</span></span><br><span class="line">        self.db[self.collection_name].insert(<span class="built_in">dict</span>(item))</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>



<h2 id="MysqlPipeline"><a href="#MysqlPipeline" class="headerlink" title="MysqlPipeline"></a>MysqlPipeline</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将项目写入MySQL</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MysqlPipeline</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,db,table,user,password</span>):</span></span><br><span class="line">		self.db = db</span><br><span class="line">		self.table = table</span><br><span class="line">		self.user = user</span><br><span class="line">		self.password = password</span><br><span class="line"></span><br><span class="line"><span class="meta">	@classmethod</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span>(<span class="params">cls,crawler</span>):</span></span><br><span class="line">		<span class="keyword">return</span> cls(</span><br><span class="line">			db = crawler.settings.get(<span class="string">&#x27;DB&#x27;</span>),</span><br><span class="line">			table = crawler.settings.get(<span class="string">&#x27;TABLE&#x27;</span>),</span><br><span class="line">			user = crawler.settings.get(<span class="string">&#x27;USER&#x27;</span>),</span><br><span class="line">			password = crawler.settings.get(<span class="string">&#x27;PASSWORD&#x27;</span>),)</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">open_spider</span>(<span class="params">self,spider</span>):</span></span><br><span class="line">		<span class="keyword">try</span>:</span><br><span class="line">			<span class="comment"># 连接数据库</span></span><br><span class="line">			self.db_conn = pymysql.connect(host=<span class="string">&#x27;localhost&#x27;</span>,user=self.user,\</span><br><span class="line">							password=self.password,port=<span class="number">3306</span>,db=self.db)</span><br><span class="line">			<span class="comment"># 如果数据库不存在</span></span><br><span class="line">		<span class="keyword">except</span> pymysql.err.InternalError:</span><br><span class="line">			<span class="comment"># 连接Mysql</span></span><br><span class="line">			self.db_conn = pymysql.connect(host=<span class="string">&#x27;localhost&#x27;</span>,user=self.user,</span><br><span class="line">	        	password=self.password,port=<span class="number">3306</span>)</span><br><span class="line">			self.cursor = self.db_conn.cursor()</span><br><span class="line">			<span class="comment"># 创建数据库</span></span><br><span class="line">			self.cursor.execute(<span class="string">&#x27;CREATE DATABASE &#123;&#125; DEFAULT CHARACTER SET utf8&#x27;</span>.<span class="built_in">format</span>(self.db))</span><br><span class="line">			<span class="comment"># 连接数据库</span></span><br><span class="line">			self.db_conn = pymysql.connect(host=<span class="string">&#x27;localhost&#x27;</span>,user=self.user,\</span><br><span class="line">				password=self.password,port=<span class="number">3306</span>,db=self.db)</span><br><span class="line">		<span class="keyword">finally</span>:</span><br><span class="line">			<span class="comment"># 创建数据库的操作游标</span></span><br><span class="line">			self.cursor = self.db_conn.cursor()</span><br><span class="line">			<span class="comment"># 建表</span></span><br><span class="line">			sql = <span class="string">&#x27;CREATE TABLE IF NOT EXISTS &#123;&#125; \</span></span><br><span class="line"><span class="string">				(title VARCHAR(255) NOT NULL,\</span></span><br><span class="line"><span class="string">				sort VARCHAR(255) NOT NULL,\</span></span><br><span class="line"><span class="string">				size VARCHAR(255) NOT NULL,\</span></span><br><span class="line"><span class="string">				href VARCHAR(255) NOT NULL,\</span></span><br><span class="line"><span class="string">				releasetime VARCHAR(255) NOT NULL,\</span></span><br><span class="line"><span class="string">				seed_num SMALLINT NOT NULL,\</span></span><br><span class="line"><span class="string">				download_time SMALLINT NOT NULL,\</span></span><br><span class="line"><span class="string">				publisher VARCHAR(255) NOT NULL,\</span></span><br><span class="line"><span class="string">				PRIMARY KEY (href))&#x27;</span>.<span class="built_in">format</span>(self.table)</span><br><span class="line">			self.cursor.execute(sql)		</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self,item,spider</span>):</span></span><br><span class="line">		keys = <span class="string">&#x27;,&#x27;</span>.join(item.keys())</span><br><span class="line">		values = <span class="string">&#x27;,&#x27;</span>.join([<span class="string">&#x27;%s&#x27;</span>] * <span class="built_in">len</span>(item))</span><br><span class="line"></span><br><span class="line">		sql = <span class="string">&#x27;INSERT INTO &#123;table&#125;(&#123;keys&#125;) values(&#123;values&#125;) ON DUPLICATE KEY UPDATE &#x27;</span>\</span><br><span class="line">		.<span class="built_in">format</span>(table=self.table,keys=keys,values=values)</span><br><span class="line">		update = <span class="string">&#x27;,&#x27;</span>.join([<span class="string">&quot;&#123;key&#125; = %s&quot;</span>.<span class="built_in">format</span>(key=key) <span class="keyword">for</span> key <span class="keyword">in</span> item])</span><br><span class="line">		sql += update</span><br><span class="line"></span><br><span class="line">		<span class="keyword">try</span>:</span><br><span class="line">		    self.cursor.execute(sql,<span class="built_in">tuple</span>(item.values())*<span class="number">2</span>)</span><br><span class="line">		    self.db_conn.commit()</span><br><span class="line">		    <span class="built_in">print</span>(<span class="string">&#x27;succeed&#x27;</span>,item[<span class="string">&#x27;title&#x27;</span>])</span><br><span class="line">		    <span class="keyword">return</span> item</span><br><span class="line">		<span class="keyword">except</span>:</span><br><span class="line">		    <span class="built_in">print</span>(<span class="string">&#x27;----------------&#x27;</span>,<span class="string">&#x27;error&#x27;</span>,item[<span class="string">&#x27;title&#x27;</span>])</span><br><span class="line">		    self.db_conn.rollback()</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">close_spider</span>(<span class="params">self,spider</span>):</span></span><br><span class="line">		self.db_conn.close()</span><br></pre></td></tr></table></figure>



<h2 id="ScreenshotPipeline"><a href="#ScreenshotPipeline" class="headerlink" title="ScreenshotPipeline"></a>ScreenshotPipeline</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 拍摄项目的屏幕截图</span></span><br><span class="line"><span class="comment"># 此示例演示如何从方法返回Deferredprocess_item()。</span></span><br><span class="line"><span class="comment"># 它使用Splash来呈现项目网址的屏幕截图。Pipeline请求本地运行的Splash实例。</span></span><br><span class="line"><span class="comment"># 在请求被下载并且Deferred回调触发后，它将项目保存到一个文件并将文件名添加到项目。</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">import</span> hashlib</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> quote</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ScreenshotPipeline</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Pipeline that uses Splash to render screenshot of</span></span><br><span class="line"><span class="string">    every Scrapy item.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    SPLASH_URL = <span class="string">&quot;http://localhost:8050/render.png?url=&#123;&#125;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self, item, spider</span>):</span></span><br><span class="line">        encoded_item_url = quote(item[<span class="string">&quot;url&quot;</span>])</span><br><span class="line">        screenshot_url = self.SPLASH_URL.<span class="built_in">format</span>(encoded_item_url)</span><br><span class="line">        request = scrapy.Request(screenshot_url)</span><br><span class="line">        dfd = spider.crawler.engine.download(request, spider)</span><br><span class="line">        dfd.addBoth(self.return_item, item)</span><br><span class="line">        <span class="keyword">return</span> dfd</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">return_item</span>(<span class="params">self, response, item</span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> response.status != <span class="number">200</span>:</span><br><span class="line">            <span class="keyword">return</span> item   <span class="comment"># Error happened, return item.</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Save screenshot to file, filename will be hash of url.</span></span><br><span class="line">        url = item[<span class="string">&quot;url&quot;</span>]</span><br><span class="line">        url_hash = hashlib.md5(url.encode(<span class="string">&quot;utf8&quot;</span>)).hexdigest()</span><br><span class="line">        filename = <span class="string">&quot;&#123;&#125;.png&quot;</span>.<span class="built_in">format</span>(url_hash)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(filename, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(response.body)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Store filename in item.</span></span><br><span class="line">        item[<span class="string">&quot;screenshot_filename&quot;</span>] = filename</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>



<h2 id="DuplicatesPipeline：项目去重"><a href="#DuplicatesPipeline：项目去重" class="headerlink" title="DuplicatesPipeline：项目去重"></a>DuplicatesPipeline：项目去重</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 复制过滤器</span></span><br><span class="line"><span class="comment"># 用于查找重复项目并删除已处理的项目的过滤器。</span></span><br><span class="line"><span class="comment"># 假设我们的项目具有唯一的ID，但是我们的蜘蛛会返回具有相同id的多个项目：</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scrapy.exceptions <span class="keyword">import</span> DropItem</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DuplicatesPipeline</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.ids_seen = <span class="built_in">set</span>()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self, item, spider</span>):</span></span><br><span class="line">        <span class="keyword">if</span> item[<span class="string">&#x27;id&#x27;</span>] <span class="keyword">in</span> self.ids_seen:</span><br><span class="line">            <span class="keyword">raise</span> DropItem(<span class="string">&quot;Duplicate item found: %s&quot;</span> % item)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.ids_seen.add(item[<span class="string">&#x27;id&#x27;</span>]) <span class="comment">#这里换成你自己的item[&quot;#&quot;]</span></span><br><span class="line">            <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>



<h2 id="RandomUserAgentMiddleware"><a href="#RandomUserAgentMiddleware" class="headerlink" title="RandomUserAgentMiddleware"></a>RandomUserAgentMiddleware</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomUserAgentMiddleware</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">process_request</span>(<span class="params">self, request, spider</span>):</span></span><br><span class="line">		request.headers.setdefault(<span class="string">&#x27;User-Agent&#x27;</span>, UserAgent().chrome)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 因为默认内建有UserAgentMiddleware，所以，在middleware里要关闭UserAgentMiddleware</span></span><br><span class="line"><span class="comment"># &#x27;scrapy.downloadermiddlewares.useragent.UserAgentMiddleware&#x27;: None,</span></span><br><span class="line"><span class="comment"># &#x27;……………….RandomUserAgentMiddleware&#x27;: 501,</span></span><br></pre></td></tr></table></figure>



<h2 id="ProxyMiddleware"><a href="#ProxyMiddleware" class="headerlink" title="ProxyMiddleware"></a>ProxyMiddleware</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ProxyMiddleware</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span>(<span class="params">self,request,spider</span>):</span></span><br><span class="line">        <span class="comment"># 添加代理</span></span><br><span class="line">        request.meta[<span class="string">&#x27;proxy&#x27;</span>] = <span class="string">&#x27;http://118.190.95.35:9001&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_response</span>(<span class="params">self,request,response,spider</span>):</span></span><br><span class="line">        response.status = <span class="number">201</span></span><br><span class="line">        <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_exception</span>(<span class="params">self,request,exception,spider</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;get exception&#x27;</span>)</span><br><span class="line">        request.meta[<span class="string">&#x27;proxy&#x27;</span>] = <span class="string">&#x27;https://45.76.96.148:12211&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> request</span><br></pre></td></tr></table></figure>



<h2 id="ChromeDownloaderMiddleware：对接selenium"><a href="#ChromeDownloaderMiddleware：对接selenium" class="headerlink" title="ChromeDownloaderMiddleware：对接selenium"></a>ChromeDownloaderMiddleware：对接selenium</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.http <span class="keyword">import</span> HtmlResponse</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.common.exceptions <span class="keyword">import</span> TimeoutException</span><br><span class="line"><span class="keyword">from</span> gp.configs <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChromeDownloaderMiddleware</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        options = webdriver.ChromeOptions()</span><br><span class="line">        options.add_argument(<span class="string">&#x27;--headless&#x27;</span>)  <span class="comment"># 设置无界面</span></span><br><span class="line">        <span class="keyword">if</span> CHROME_PATH:</span><br><span class="line">            options.binary_location = CHROME_PATH</span><br><span class="line">        <span class="keyword">if</span> CHROME_DRIVER_PATH:</span><br><span class="line">            self.driver = webdriver.Chrome(chrome_options=options, executable_path=CHROME_DRIVER_PATH)  <span class="comment"># 初始化Chrome驱动</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.driver = webdriver.Chrome(chrome_options=options)  <span class="comment"># 初始化Chrome驱动</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__del__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.driver.close()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span>(<span class="params">self, request, spider</span>):</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Chrome driver begin...&#x27;</span>)</span><br><span class="line">            self.driver.get(request.url)  <span class="comment"># 获取网页链接内容</span></span><br><span class="line">            <span class="keyword">return</span> HtmlResponse(url=request.url, body=self.driver.page_source, request=request, encoding=<span class="string">&#x27;utf-8&#x27;</span>,</span><br><span class="line">                                status=<span class="number">200</span>)  <span class="comment"># 返回HTML数据</span></span><br><span class="line">        <span class="keyword">except</span> TimeoutException:</span><br><span class="line">            <span class="keyword">return</span> HtmlResponse(url=request.url, request=request, encoding=<span class="string">&#x27;utf-8&#x27;</span>, status=<span class="number">500</span>)</span><br><span class="line">        <span class="keyword">finally</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Chrome driver end...&#x27;</span>)</span><br></pre></td></tr></table></figure>



<h2 id="TaobaoSpider"><a href="#TaobaoSpider" class="headerlink" title="TaobaoSpider"></a>TaobaoSpider</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> Request, Spider</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> quote</span><br><span class="line"><span class="keyword">from</span> scrapyseleniumtest.items <span class="keyword">import</span> ProductItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TaobaoSpider</span>(<span class="params">Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;taobao&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;www.taobao.com&#x27;</span>]</span><br><span class="line">    base_url = <span class="string">&#x27;https://s.taobao.com/search?q=&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">for</span> keyword <span class="keyword">in</span> self.settings.get(<span class="string">&#x27;KEYWORDS&#x27;</span>):</span><br><span class="line">            <span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, self.settings.get(<span class="string">&#x27;MAX_PAGE&#x27;</span>) + <span class="number">1</span>):</span><br><span class="line">                url = self.base_url + quote(keyword)</span><br><span class="line">                <span class="keyword">yield</span> Request(url=url, callback=self.parse, meta=&#123;<span class="string">&#x27;page&#x27;</span>: page&#125;, dont_filter=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        products = response.xpath(</span><br><span class="line">            <span class="string">&#x27;//div[@id=&quot;mainsrp-itemlist&quot;]//div[@class=&quot;items&quot;][1]//div[contains(@class, &quot;item&quot;)]&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> product <span class="keyword">in</span> products:</span><br><span class="line">            item = ProductItem()</span><br><span class="line">            item[<span class="string">&#x27;price&#x27;</span>] = <span class="string">&#x27;&#x27;</span>.join(product.xpath(<span class="string">&#x27;.//div[contains(@class, &quot;price&quot;)]//text()&#x27;</span>).extract()).strip()</span><br><span class="line">            item[<span class="string">&#x27;title&#x27;</span>] = <span class="string">&#x27;&#x27;</span>.join(product.xpath(<span class="string">&#x27;.//div[contains(@class, &quot;title&quot;)]//text()&#x27;</span>).extract()).strip()</span><br><span class="line">            item[<span class="string">&#x27;shop&#x27;</span>] = <span class="string">&#x27;&#x27;</span>.join(product.xpath(<span class="string">&#x27;.//div[contains(@class, &quot;shop&quot;)]//text()&#x27;</span>).extract()).strip()</span><br><span class="line">            item[<span class="string">&#x27;image&#x27;</span>] = <span class="string">&#x27;&#x27;</span>.join(product.xpath(<span class="string">&#x27;.//div[@class=&quot;pic&quot;]//img[contains(@class, &quot;img&quot;)]/@data-src&#x27;</span>).extract()).strip()</span><br><span class="line">            item[<span class="string">&#x27;deal&#x27;</span>] = product.xpath(<span class="string">&#x27;.//div[contains(@class, &quot;deal-cnt&quot;)]//text()&#x27;</span>).extract_first()</span><br><span class="line">            item[<span class="string">&#x27;location&#x27;</span>] = product.xpath(<span class="string">&#x27;.//div[contains(@class, &quot;location&quot;)]//text()&#x27;</span>).extract_first()</span><br><span class="line">            <span class="keyword">yield</span> item</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">####################################################################################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.common.exceptions <span class="keyword">import</span> TimeoutException</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support.ui <span class="keyword">import</span> WebDriverWait</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support <span class="keyword">import</span> expected_conditions <span class="keyword">as</span> EC</span><br><span class="line"><span class="keyword">from</span> scrapy.http <span class="keyword">import</span> HtmlResponse</span><br><span class="line"><span class="keyword">from</span> logging <span class="keyword">import</span> getLogger</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SeleniumMiddleware</span>():</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, timeout=<span class="literal">None</span>, service_args=[]</span>):</span></span><br><span class="line">        self.logger = getLogger(__name__)</span><br><span class="line">        self.timeout = timeout</span><br><span class="line">        self.browser = webdriver.PhantomJS(service_args=service_args)</span><br><span class="line">        self.browser.set_window_size(<span class="number">1400</span>, <span class="number">700</span>)</span><br><span class="line">        self.browser.set_page_load_timeout(self.timeout)</span><br><span class="line">        self.wait = WebDriverWait(self.browser, self.timeout)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__del__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.browser.close()</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span>(<span class="params">self, request, spider</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        用PhantomJS抓取页面</span></span><br><span class="line"><span class="string">        :param request: Request对象</span></span><br><span class="line"><span class="string">        :param spider: Spider对象</span></span><br><span class="line"><span class="string">        :return: HtmlResponse</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.logger.debug(<span class="string">&#x27;PhantomJS is Starting&#x27;</span>)</span><br><span class="line">        page = request.meta.get(<span class="string">&#x27;page&#x27;</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            self.browser.get(request.url)</span><br><span class="line">            <span class="keyword">if</span> page &gt; <span class="number">1</span>:</span><br><span class="line">                <span class="built_in">input</span> = self.wait.until(</span><br><span class="line">                    EC.presence_of_element_located((By.CSS_SELECTOR, <span class="string">&#x27;#mainsrp-pager div.form &gt; input&#x27;</span>)))</span><br><span class="line">                submit = self.wait.until(</span><br><span class="line">                    EC.element_to_be_clickable((By.CSS_SELECTOR, <span class="string">&#x27;#mainsrp-pager div.form &gt; span.btn.J_Submit&#x27;</span>)))</span><br><span class="line">                <span class="built_in">input</span>.clear()</span><br><span class="line">                <span class="built_in">input</span>.send_keys(page)</span><br><span class="line">                submit.click()</span><br><span class="line">            self.wait.until(</span><br><span class="line">                EC.text_to_be_present_in_element((By.CSS_SELECTOR, <span class="string">&#x27;#mainsrp-pager li.item.active &gt; span&#x27;</span>), <span class="built_in">str</span>(page)))</span><br><span class="line">            self.wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, <span class="string">&#x27;.m-itemlist .items .item&#x27;</span>)))</span><br><span class="line">            <span class="keyword">return</span> HtmlResponse(url=request.url, body=self.browser.page_source, request=request, encoding=<span class="string">&#x27;utf-8&#x27;</span>,</span><br><span class="line">                                status=<span class="number">200</span>)</span><br><span class="line">        <span class="keyword">except</span> TimeoutException:</span><br><span class="line">            <span class="keyword">return</span> HtmlResponse(url=request.url, status=<span class="number">500</span>, request=request)</span><br><span class="line">    </span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span>(<span class="params">cls, crawler</span>):</span></span><br><span class="line">        <span class="keyword">return</span> cls(timeout=crawler.settings.get(<span class="string">&#x27;SELENIUM_TIMEOUT&#x27;</span>),</span><br><span class="line">                   service_args=crawler.settings.get(<span class="string">&#x27;PHANTOMJS_SERVICE_ARGS&#x27;</span>))</span><br></pre></td></tr></table></figure>

</div></div></article><link rel="stylesheet" type="text/css" href="/css/font.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.css"><script src="//cdn.bootcss.com/jquery/2.0.3/jquery.min.js"></script><script src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js"></script><script>$(document).ready(function() {
  $(".fancybox").fancybox();
});
</script></body></html>