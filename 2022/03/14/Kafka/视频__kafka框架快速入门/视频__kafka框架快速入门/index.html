<!DOCTYPE html><html><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content=" id=&quot;kafka简介&quot;&gt;&lt;a href=&quot;#kafka简介&quot; class=&quot;headerlink&quot; title=&quot;kafka简介&quot;&gt;&lt;/a&gt;kafka简介&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Kafka是一个&lt;code&gt;分布式&lt;/code&gt;的基于&lt;strong&gt;发布/订阅模式&lt;/strong&gt;的消息队列（Message Queue），主要应用于大数据实时处理领域。&lt;/li&gt;
&lt;li&gt;Kafka对消息保存时根据Topic进行归类，发送消息者称为Producer。消息接受者称为 Consumer，&lt;/li&gt;
&lt;li&gt;此外Kafka集群由多个Kafka实例组成，&lt;strong&gt;每个实例(server)称为 broker&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;无论是Kafka集群，还是producer和 consume都依赖于zookeeper集群保存一些meta信息，来保证系统可用性&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Kafka架构&quot;&gt;&lt;a href=&quot;#Kafka架构&quot; class=&quot;headerlink&quot; title=&quot;Kafka架构&quot;&gt;&lt;/a&gt;Kafka架构&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/images/1593923964930.png&quot; alt=&quot;1593923964930&quot;&gt;"><link rel="stylesheet" type="text/css" href="/css/normalize.css"><link rel="stylesheet" type="text/css" href="/css/highlight.css"><link rel="stylesheet" type="text/css" href="/css/noise.css"><title>kafka框架快速入门 | 凉薄的自动书记人偶</title><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><meta name="generator" content="Hexo 5.4.0"></head><body><article class="wrapper"><div class="post-main"><div class="nav"><nav class="container"><a class="sidebar-nav-item active" href="/">Home</a><a class="sidebar-nav-item" href="/archives">Tags</a><a class="sidebar-nav-item" href="/About">About</a></nav><div class="container post-meta"><div class="post-tags"><a class="post-tag-link" href="/tags/Kafka/" rel="tag">Kafka</a></div><div class="post-time">2022-03-14</div></div></div><div class="container post-header"><h1>kafka框架快速入门</h1></div><div class="container post-toc"><details class="toc"><summary class="toc-accordion">Table of Contents</summary><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#kafka%E7%AE%80%E4%BB%8B"><span class="toc-number">1.</span> <span class="toc-text">kafka简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka%E6%9E%B6%E6%9E%84"><span class="toc-number">2.</span> <span class="toc-text">Kafka架构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%9B%E5%A4%A7%E6%A0%B8%E5%BF%83%E6%8E%A5%E5%8F%A3"><span class="toc-number">2.1.</span> <span class="toc-text">四大核心接口</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Topic"><span class="toc-number">2.2.</span> <span class="toc-text">Topic</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.3.</span> <span class="toc-text">消费模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E7%BB%84"><span class="toc-number">2.4.</span> <span class="toc-text">消费组</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Partition-%E4%B8%8E-Consumer-%E7%9A%84%E5%AF%B9%E5%BA%94%E5%85%B3%E7%B3%BB"><span class="toc-number">2.5.</span> <span class="toc-text">Partition 与 Consumer 的对应关系</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%A9%E7%90%86%E5%AD%98%E5%82%A8"><span class="toc-number">2.6.</span> <span class="toc-text">物理存储</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A6%82%E5%BF%B5%E5%B0%8F%E7%BB%93"><span class="toc-number">2.7.</span> <span class="toc-text">概念小结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka-%E6%9E%B6%E6%9E%84%E6%B7%B1%E5%85%A5"><span class="toc-number">3.</span> <span class="toc-text">Kafka 架构深入</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka-%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%E5%8F%8A%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6"><span class="toc-number">3.1.</span> <span class="toc-text">Kafka 工作流程及文件存储机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka-%E7%94%9F%E4%BA%A7%E8%80%85"><span class="toc-number">3.2.</span> <span class="toc-text">Kafka 生产者</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5"><span class="toc-number">3.2.1.</span> <span class="toc-text">分区策略</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BF%9D%E8%AF%81"><span class="toc-number">3.2.2.</span> <span class="toc-text">数据可靠性保证</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E5%9C%A8Kafka%E4%B8%AD%E7%9A%84%E5%8E%86%E7%A8%8B"><span class="toc-number">4.</span> <span class="toc-text">消息在Kafka中的历程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#kafka%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">5.</span> <span class="toc-text">kafka使用场景</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E6%81%AFMessaging"><span class="toc-number">5.1.</span> <span class="toc-text">消息Messaging</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E7%AB%99%E6%B4%BB%E5%8A%A8%E8%B7%9F%E8%B8%AA"><span class="toc-number">5.2.</span> <span class="toc-text">网站活动跟踪</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BA%A6%E9%87%8FMetrics"><span class="toc-number">5.3.</span> <span class="toc-text">度量Metrics</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%A5%E5%BF%97%E8%81%9A%E5%90%88"><span class="toc-number">5.4.</span> <span class="toc-text">日志聚合</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B5%81%E5%A4%84%E7%90%86"><span class="toc-number">5.5.</span> <span class="toc-text">流处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Event-Sourcing"><span class="toc-number">5.6.</span> <span class="toc-text">Event Sourcing</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8F%90%E4%BA%A4%E6%97%A5%E5%BF%97"><span class="toc-number">5.7.</span> <span class="toc-text">提交日志</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka-%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%93%8D%E4%BD%9C"><span class="toc-number">6.</span> <span class="toc-text">Kafka 命令行操作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Demo%EF%BC%9AWordCount"><span class="toc-number">7.</span> <span class="toc-text">Demo：WordCount</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%88%9B%E5%BB%BA%E8%BE%93%E5%85%A5Topic"><span class="toc-number">7.1.</span> <span class="toc-text">1. 创建输入Topic</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%90%91Topic%E8%BE%93%E5%85%A5%E6%B6%88%E6%81%AF"><span class="toc-number">7.2.</span> <span class="toc-text">2. 向Topic输入消息</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E6%B5%81%E5%A4%84%E7%90%86%E9%80%BB%E8%BE%91"><span class="toc-number">7.3.</span> <span class="toc-text">3. 流处理逻辑</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%90%AF%E5%8A%A8%E5%A4%84%E7%90%86%E9%80%BB%E8%BE%91"><span class="toc-number">7.4.</span> <span class="toc-text">4. 启动处理逻辑</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E5%90%AF%E5%8A%A8%E6%B6%88%E8%B4%B9%E8%80%85%E8%BF%9B%E7%A8%8B"><span class="toc-number">7.5.</span> <span class="toc-text">5. 启动消费者进程</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#reference"><span class="toc-number"></span> <span class="toc-text">reference</span></a></details></div><div class="container post-content"><h2 id="kafka简介"><a href="#kafka简介" class="headerlink" title="kafka简介"></a>kafka简介</h2><ul>
<li>Kafka是一个<code>分布式</code>的基于<strong>发布/订阅模式</strong>的消息队列（Message Queue），主要应用于大数据实时处理领域。</li>
<li>Kafka对消息保存时根据Topic进行归类，发送消息者称为Producer。消息接受者称为 Consumer，</li>
<li>此外Kafka集群由多个Kafka实例组成，<strong>每个实例(server)称为 broker</strong></li>
<li>无论是Kafka集群，还是producer和 consume都依赖于zookeeper集群保存一些meta信息，来保证系统可用性</li>
</ul>
<h2 id="Kafka架构"><a href="#Kafka架构" class="headerlink" title="Kafka架构"></a>Kafka架构</h2><p><img src="/images/1593923964930.png" alt="1593923964930"></p>
<ul>
<li><strong>Topic ：可以理解为一个队列</strong>，生产者和消费者面向的都是一个 topic</li>
<li>Partition：为了实现扩展性，一个非常大的 topic 可以分布到多个 broker（即服务器）上，一个 topic 可以分为多个 partition，每个 partition 是一个有序的队列</li>
<li>Replica：副本，为保证集群中的某个节点发生故障时，该节点上的 partition 数据不丢失，且 kafka 仍然能够继续工作，kafka 提供了副本机制，一个 topic 的每个分区都有若干个副本，一个 leader 和若干个 follower。<ul>
<li>leader：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是 leader。</li>
<li>follower：每个分区多个副本中的“从”，实时从 leader 中同步数据，保持和leader 数据的同步。leader 发生故障时，某个 follower 会成为新的 follower。</li>
</ul>
</li>
<li>Consumer Group （CG）：消费者组，由多个 consumer 组成。消费者组内<strong>每个消费者负责消费不同分区的数据</strong>，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</li>
<li><code>特定分区的数据</code>只能被一个消费者组的<code>某一个特定消费者</code>进行消费所以 , 当<code>消费者组的消费者数量</code> == <code>主题的分区数</code> 时 , 消费的效率最高</li>
</ul>
<blockquote>
<p>分区(Partition)是用来提高并行度的，而副本(Replica)是容灾备份的</p>
</blockquote>
<h3 id="四大核心接口"><a href="#四大核心接口" class="headerlink" title="四大核心接口"></a>四大核心接口</h3><p>Kafka为了拥有更强大的功能，提供了四大核心接口：</p>
<ul>
<li><code>Producer API</code>允许了应用可以向Kafka中的topics发布消息；</li>
<li><code>Consumer API</code>允许了应用可以订阅Kafka中的topics，并消费消息；</li>
<li><code>Streams API</code>允许应用可以作为消息流的处理者，比如可以<strong>从topicA中消费消息，处理的结果发布到topicB中</strong>；</li>
<li><code>Connector API</code>提供Kafka与现有的应用或系统适配功能，比如与数据库连接器可以捕获表结构的变化；</li>
</ul>
<p>它们与Kafka集群的关系可以用下图表示：</p>
<p><img src="/images/kafka-apis.png" alt="kafka-apis"></p>
<h3 id="Topic"><a href="#Topic" class="headerlink" title="Topic"></a>Topic</h3><p>一个 Topic（主题）对应一个消息队列。Kafka 支持多生产者，多消费者，对应下图：</p>
<p><img src="/images/kafka-topic.svg" alt="Kafka Topic"></p>
<ul>
<li>多个生产者将数据发送到 Kafka 中，Kafka 将它们顺序存储。</li>
<li>Kafka 的目标是大数据，如果将消息存在一个“中心”队列中，势必缺少可伸缩性。无论是生产者/消费者数目的增加，还是消息数量的增加，都可能耗尽机器的性能或存储。</li>
<li>因此，Kafka <strong>在概念上将一个 Topic 分成了多个 Partition，写入 topic 的消息会被（平均）分配到其中一个 Partition</strong>。Partition 中会为消息保存一个 Partition 内唯一的 ID ，一般称为偏移量(<code>offset</code>)。这样当性能/存储不足时 Kafka 就可以通过增加 Partition 实现横向扩展。</li>
</ul>
<p><img src="/images/kafka-partition.svg" alt="Kafka Partition"></p>
<blockquote>
<p>Partition 的本质是负载均衡。</p>
</blockquote>
<h3 id="消费模型"><a href="#消费模型" class="headerlink" title="消费模型"></a>消费模型</h3><p>一般有两种消费模型，不同模型下消费者的行为是不同的：</p>
<ul>
<li><code>队列模式</code>（也叫点对点模式）。多个消费者共同消费一个队列，<strong>每条消息只发送给一个消费者</strong>。</li>
<li><code>发布/订阅模式</code>。多个消费者订阅主题，<strong>每个消息会发布给所有的消费者</strong>。</li>
</ul>
<p><img src="/images/kafka-consumer-model.svg" alt="Kafka Consumer Model"></p>
<p>两种方式各有优缺点：</p>
<ul>
<li>队列模式中多个消费者共同消费同一个队列，效率高。</li>
<li>发布/订阅模式中，一个消息可以被多次消费，能支持冗余的消费（例如两个消费者共同消费一个消息，防止其中某个消费者挂了）</li>
</ul>
<p>显然要构建一个大数据下的消息队列，<strong>两种模式都是必须的</strong>。</p>
<h3 id="消费组"><a href="#消费组" class="headerlink" title="消费组"></a>消费组</h3><p>Consumer Group （<code>消费组</code>）是以发布/订阅模式工作的；</p>
<p>一个 Consumer Group 中可以有多个 Consumer（消费者），<strong>消费组内的消费者以队列模式工作，每个消费者负责消费不同分区的数据</strong>。如下图：</p>
<p><img src="/images/kafka-consumer-group.svg" alt="Kafka Consumer Group"></p>
<h3 id="Partition-与-Consumer-的对应关系"><a href="#Partition-与-Consumer-的对应关系" class="headerlink" title="Partition 与 Consumer 的对应关系"></a>Partition 与 Consumer 的对应关系</h3><p>上面提到，Kafka 中<strong>一个 topic 中的消息是被打散分配在多个 Partition(分区) 中存储的</strong>， Consumer Group 在消费时需要从不同的 Partition 获取消息，那最终如何重建出 Topic 中消息的顺序呢？</p>
<p>答案是：没有办法。Kafka 只会保证在 Partition 内消息是有序的，而不管全局的情况。这么理解：</p>
<ol>
<li>一个 Topic（主题）对应一个消息队列。也就是说，一个Topic对应一个流水线。</li>
<li>当流水线只有一条的时候，流水线崩了，则全部停摆。为了防止这种情况，需要将一条流水线拆成多条小流水线，当一条消息过来的时候，按规则将其分配给其中一条小流水线，这就是Partition。其实本质就是负载均衡。</li>
<li>因为不同的小流水线的流速不同，因此是不能保证全局的消息是按序输出的。但是能保证每条小流水线是按序的。</li>
</ol>
<p>Partition 中的消息可以被（不同的 Consumer Group）多次消费，那 Partition中被消费的消息是何时删除的？ Partition 又是如何知道一个 Consumer Group 当前消费的位置呢？</p>
<ol>
<li>无论消息是否被消费，<strong>除非消息到期 Partition 从不删除消息</strong>。例如设置保留时间为 2 天，则消息发布 2 天内任何 Group 都可以消费，2 天后，消息自动被删除。</li>
<li>Partition 会为每个 Consumer Group 保存一个偏移量，记录 Group 消费到的位置。如下图：</li>
</ol>
<p><img src="/images/kafka-consumer-position.svg" alt="Kafka Consumer Position"></p>
<p>上面我们提到的都是 Partition 与 Consumer Group 之间的关系，那 Group 中的 Consumer 又是如何与 Partition 对应的呢？其实机制很简单：</p>
<ul>
<li>同一个 Consumer Group 内，一个 Partition 只能被一个 Consumer 消费。</li>
<li>所以：如果 Consumer 的数量大于 Partition 数量，则会有 Consumer 是空闲的。如果 Consumer 的数量小于 Partition 数量，则一个 Consumer 可能消费多个 Partition。</li>
</ul>
<p><img src="/images/kafka-partition-consumer.svg" alt="Kafka Partition Consumer Relationship"></p>
<p>左边的 Consumer Group 中的 C4 是空闲的，而右边 Group 中的 C1 则需要消费两个 Partition 。由于 C1 中消息可能来源于两个 Partition，此时如果需要确保消息的顺序，必须先判断消息的 Partition ID。</p>
<p>在分配 Partition 时，肯定是希望不同的 Consumer 的负载大致相同，具体的分配算法有 <code>Range</code> 的 <code>RoundRobin</code> 两种。</p>
<h3 id="物理存储"><a href="#物理存储" class="headerlink" title="物理存储"></a>物理存储</h3><p>上面提到的 Topic, Partition 都是抽象的概念。<strong>每个 Partition 最终都需要存储在物理机器上</strong>，在 Kafka 中一般把这样的物理机器称为 <code>Broker</code>，可以是一台物理机，也可以是一个集群。</p>
<p>考虑到物理机可能会损坏，这会导致某个 Partition 失效，导致上面存储的消息丢失。所以一般需要对数据做冗余 (replication)。<strong>换言之，需要存储多份 Partition 在不同的 Broker 上</strong>，并为它们的数据进行同步。</p>
<p>那么从物理的视角：</p>
<p><img src="/images/kafka-broker.svg" alt="Kafka Partition Broker View"></p>
<p>上图中，某个 Topic 分成了 3 个 Partition，每个 Partition 保存了两个副本，副本平均分配到 3 个 Broker 上。图中即使有一个 Broker 挂了，剩余的两个 Broker 依旧能正常工作。这也是分布式系统的常用设计。</p>
<p>同一个 Partition 有多个副本，并分布在不同的 Broker 上，那么 Producer 应该写入到哪一个副本上呢？Consumer 又应该从哪个副本上读取呢？</p>
<ol>
<li>Kafka 的各个 Broker 需要与 Zookeeper 进行通信，每个 Partition 的多个副本之间通过 Zookeeper 的 Leader 选举机制选出主副本。所有该 Partition 上的读写都通过这个主副本进行。</li>
<li>其它的冗余副本会从主副本上同步新的消息。就像其它的 Consumer 一样。</li>
</ol>
<h3 id="概念小结"><a href="#概念小结" class="headerlink" title="概念小结"></a>概念小结</h3><ol>
<li>Topic 是顶级概念，对应于一个消息队列。</li>
<li>Kafka 是以 Partition 为单位存储消息的，Consumer 在消费时也是按 Partition 进行的。即 Kafka 会保证一个 Consumer 收到的消息中，来自同一个 Partition 的所有消息是有序的。而来自不同 Partition 的消息则不保证有序。</li>
<li>Partition 会为其中的消息分配 Partition 内唯一的 ID，一般称作偏移量(offset) 。Kafka 会保留所有的消息，直到消息的保留时间（例如设置保留 2 天）结束。这样 Consumer 可以自由决定如何读取消息，例如读取更早的消息，重新消费等。</li>
<li>Kafka 有 Consumer Group 的概念。每个 Group 独立消费某个 Topic 的消息，互相不干扰。事实上，Kafka 会为每个 Group 保存一个偏移量，记录消费的位置。每个 Group 可以包含多个 Consumer，它们共同消费这个 Topic。</li>
<li>对于一个 Consumer Group，一个 Partition 只能由 Group 中的一个 Consumer 消费。具体哪个 Consumer 监听哪个 Partition 是由 Kafka 分配的。算法可以指定为 <code>Range</code> 或 <code>RoundRobin</code>。</li>
<li>物理上，消息是存在 Broker 上的，一般对应为一台物理机或集群。存储时，每个 Partition 都可以有多个副本。它们会被“均匀”地存储在各个 Broker 中。</li>
<li>对于一个 Partition，它的多个复本存储一般存储在不同 Broker 中，在同一时刻会由 Zookeeper 选出一个主副本来负责所有的读写操作。</li>
</ol>
<p>另外，随着 Kafka 的发展，它的定位已经从“分布式消息队列”变成了“分布式流处理平台”，添加了 Connector 及 Stream Processor 的概念。只是这些并不改变它的基本概念和结构。</p>
<h2 id="Kafka-架构深入"><a href="#Kafka-架构深入" class="headerlink" title="Kafka 架构深入"></a>Kafka 架构深入</h2><h3 id="Kafka-工作流程及文件存储机制"><a href="#Kafka-工作流程及文件存储机制" class="headerlink" title="Kafka 工作流程及文件存储机制"></a>Kafka 工作流程及文件存储机制</h3><p><img src="/images/image-20210806114629730.png" alt="image-20210806114629730"></p>
<ul>
<li>Kafka 中消息是以 topic 进行分类的，生产者生产消息，消费者消费消息，都是<strong>面向 topic</strong> 的。 </li>
<li>topic 是逻辑上的概念，而 partition 是物理上的概念，每个 partition 对应于一个 log 文 件，该 log 文件中存储的就是 producer 生产的数据。Producer 生产的数据会被不断追加到该 log 文件末端，且每条数据都有自己的 offset。消费者组中的每个消费者，都会实时记录自己消费到了哪个 offset，以便出错恢复时，从上次的位置继续消费。</li>
</ul>
<p><img src="/images/image-20210806114911560.png" alt="image-20210806114911560"></p>
<ul>
<li>由于生产者生产的消息会不断追加到 log 文件末尾，为防止 log 文件过大导致数据定位效率低下，Kafka 采取了分片和索引机制，</li>
<li>将每个 partition 分为多个 segment。每个 segment 对应两个文件——“.index”文件和“.log”文件。这些文件位于一个文件夹下，该文件夹的命名 规则为：<code>topic 名称+分区序号</code>。</li>
<li>例如，first 这个 topic 有三个分区，则其对应的文件夹为 first0,first-1,first-2。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">00000000000000000000.index</span><br><span class="line">00000000000000000000.log</span><br><span class="line">00000000000000170410.index</span><br><span class="line">00000000000000170410.log</span><br><span class="line">00000000000000239430.index</span><br><span class="line">00000000000000239430.log</span><br></pre></td></tr></table></figure>



<p>index 和 log 文件以当前 segment 的第一条消息的 offset 命名。下图为 index 文件和 log 文件的结构示意图。</p>
<p><img src="/images/image-20210806115205065.png" alt="image-20210806115205065"></p>
<ul>
<li><code>.index”</code>文件存储大量的索引信息，</li>
<li><code>.log</code>文件存储大量的数据，索引文件中的元数据指向对应数据文件中 message 的物理偏移地址。</li>
</ul>
<h3 id="Kafka-生产者"><a href="#Kafka-生产者" class="headerlink" title="Kafka 生产者"></a>Kafka 生产者</h3><h4 id="分区策略"><a href="#分区策略" class="headerlink" title="分区策略"></a>分区策略</h4><p>分区的原因：</p>
<ol>
<li>方便在集群中扩展，每个 Partition 可以通过调整以适应它所在的机器，而一个 topic 又可以有多个 Partition 组成，因此整个集群就可以适应任意大小的数据了；</li>
<li>可以提高并发，因为可以以 Partition 为单位读写了。</li>
</ol>
<p>分区的原则：</p>
<p>我们需要将 producer 发送的数据封装成一个 ProducerRecord 对象。</p>
<p><img src="/images/image-20210806115925337.png" alt="image-20210806115925337"></p>
<ol>
<li>指明 partition 的情况下，直接将指明的值直接作为 partiton 值； </li>
<li>没有指明 partition 值但有 key 的情况下，将 key 的 hash 值与 topic 的 partition 数进行取余得到 partition 值； </li>
<li>既没有 partition 值又没有 key 值的情况下，第一次调用时随机生成一个整数（后 面每次调用在这个整数上自增），将这个值与 topic 可用的 partition 总数取余得到 partition 值，也就是常说的 round-robin 算法。</li>
</ol>
<h4 id="数据可靠性保证"><a href="#数据可靠性保证" class="headerlink" title="数据可靠性保证"></a>数据可靠性保证</h4><p>为保证 producer 发送的数据，能可靠的发送到指定的 topic，topic 的每个 partition 收到 producer 发送的数据后，都需要向 producer 发送 ack（acknowledgement 确认收到），如果 producer 收到 ack，就会进行下一轮的发送，否则重新发送数据。</p>
<p><img src="/images/image-20210806120138525.png" alt="image-20210806120138525"></p>
<p>副本数据同步策略：</p>
<table>
<thead>
<tr>
<th>方案</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody><tr>
<td>半数以上完成同步，就发送ack</td>
<td>延迟低</td>
<td>选举新的leader时，容忍n台节点故障，需要2n+1个副本</td>
</tr>
<tr>
<td>全部完成同步，财大送ack</td>
<td>选举新的leader时，容忍n台节点故障，需要n+1个副本</td>
<td>延迟高</td>
</tr>
</tbody></table>
<p>Kafka 选择了第二种方案，原因如下： </p>
<ol>
<li>同样为了容忍 n 台节点的故障，第一种方案需要 2n+1 个副本，而第二种方案只需要 n+1 个副本，而 Kafka 的每个分区都有大量的数据，第一种方案会造成大量数据的冗余。 </li>
<li>虽然第二种方案的网络延迟会比较高，但网络延迟对 Kafka 的影响较小。</li>
</ol>
<h2 id="消息在Kafka中的历程"><a href="#消息在Kafka中的历程" class="headerlink" title="消息在Kafka中的历程"></a>消息在Kafka中的历程</h2><p>一条消息从发出到最后被消息者接收到底经历了什么</p>
<p><img src="/images/message-flow.png" alt="message-flow"></p>
<p>上图简要的说明了消息在Kafka中的整个流转过程：</p>
<ol>
<li>消息生产者将消息发布到具体的Topic，根据一定算法或者随机被分发到具体的partition中；</li>
<li>根据实际需求，是否需要实现处理消息逻辑；若需要，则实现具体逻辑后将结果发布到输出Topic；</li>
<li>消费者根据需求订阅相关Topic，并消费消息；</li>
</ol>
<h2 id="kafka使用场景"><a href="#kafka使用场景" class="headerlink" title="kafka使用场景"></a>kafka使用场景</h2><h3 id="消息Messaging"><a href="#消息Messaging" class="headerlink" title="消息Messaging"></a>消息Messaging</h3><ul>
<li><strong>Kafka可以替代更传统的消息代理</strong>。消息代理的使用有多种原因（将处理与数据生成器分离，缓冲未处理的消息等）。</li>
<li><strong>与大多数消息传递系统相比，Kafka具有更好的吞吐量，内置分区，复制和容错功能</strong>，这使其成为大规模消息处理应用程序的理想解决方案。</li>
<li>根据经验，消息传递的使用通常相对较低，但可能需要较低的端到端延迟，并且通常取决于Kafka提供的强大的耐用性保证。</li>
<li>在这个领域，Kafka可与传统的消息传递系统（如<a target="_blank" rel="noopener" href="http://activemq.apache.org/">ActiveMQ</a>或 <a target="_blank" rel="noopener" href="https://www.rabbitmq.com/">RabbitMQ</a>）相媲美。</li>
</ul>
<h3 id="网站活动跟踪"><a href="#网站活动跟踪" class="headerlink" title="网站活动跟踪"></a>网站活动跟踪</h3><ul>
<li>Kafka的原始用例是能够将用户活动跟踪管道重建为一组实时发布 - 订阅源。这意味着站点活动（页面查看，搜索或用户可能采取的其他操作）将发布到中心主题，每个活动类型包含一个主题。这些源可用于订购一系列用例，<strong>包括实时处理，实时监控以及加载到Hadoop或离线数据仓库系统以进行脱机处理和报告</strong>。</li>
<li>活动跟踪通常非常高，因为为每个用户页面视图生成了许多活动消息。</li>
</ul>
<h3 id="度量Metrics"><a href="#度量Metrics" class="headerlink" title="度量Metrics"></a>度量Metrics</h3><p><strong>Kafka通常用于运营监控数据</strong>。这涉及从分布式应用程序聚合统计信息以生成操作数据的集中式提要。</p>
<h3 id="日志聚合"><a href="#日志聚合" class="headerlink" title="日志聚合"></a>日志聚合</h3><ul>
<li>许多人使用Kafka作为日志聚合解决方案的替代品。</li>
<li>日志聚合通常从服务器收集物理日志文件，并将它们放在中央位置（可能是文件服务器或HDFS）进行处理。<strong>Kafka抽象出文件的细节，并将日志或事件数据作为消息流更清晰地抽象出来</strong>。这允许更低延迟的处理并更容易支持多个数据源和分布式数据消耗。</li>
<li>与Scribe或Flume等以日志为中心的系统相比，<strong>Kafka提供了同样出色的性能，由于复制而具有更强的耐用性保证，以及更低的端到端延迟。</strong></li>
</ul>
<h3 id="流处理"><a href="#流处理" class="headerlink" title="流处理"></a>流处理</h3><ul>
<li>许多Kafka用户在处理由多个阶段组成的管道时处理数据，<strong>其中原始输入数据从Kafka主题中消费，然后聚合，丰富或以其他方式转换为新主题以供进一步消费或后续处理</strong>。</li>
<li>例如，用于推荐新闻文章的处理管道可以从RSS订阅源抓取文章内容并将其发布到“文章”主题; 进一步处理可能会对此内容进行规范化或重复数据删除，并将已清理的文章内容发布到新主题; 最终处理阶段可能会尝试向用户推荐此内容。此类处理管道基于各个主题创建实时数据流的图形。从0.10.0.0开始，这是一个轻量级但功能强大的流处理库，名为<a target="_blank" rel="noopener" href="http://kafka.apache.org/documentation/streams">Kafka Streams</a> 在Apache Kafka中可用于执行如上所述的此类数据处理。</li>
<li>除了Kafka Streams之外，其他开源流处理工具包括<a target="_blank" rel="noopener" href="https://storm.apache.org/">Apache Storm</a>和 <a target="_blank" rel="noopener" href="http://samza.apache.org/">Apache Samza</a>。</li>
</ul>
<h3 id="Event-Sourcing"><a href="#Event-Sourcing" class="headerlink" title="Event Sourcing"></a>Event Sourcing</h3><p>Event Sourcing是一种应用程序设计风格，其中状态更改记录为按时间排序的记录序列。Kafka对非常大的存储日志数据的支持使其成为以这种风格构建的应用程序的出色后端。</p>
<h3 id="提交日志"><a href="#提交日志" class="headerlink" title="提交日志"></a>提交日志</h3><p><strong>Kafka可以作为分布式系统的一种外部提交日志</strong>。该日志有助于在节点之间复制数据，并充当故障节点恢复其数据的重新同步机制。Kafka中的日志压缩功能有助于支持此用法。在这种用法中，Kafka类似于<a target="_blank" rel="noopener" href="https://bookkeeper.apache.org/">Apache BookKeeper</a>项目。</p>
<h2 id="Kafka-命令行操作"><a href="#Kafka-命令行操作" class="headerlink" title="Kafka 命令行操作"></a>Kafka 命令行操作</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看当前服务器中的所有 topic</span></span><br><span class="line">bin/kafka-topics.sh --zookeeper 188.66.88.15:2181 --list</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 topic :</span></span><br><span class="line"><span class="comment"># 创建一个名叫first的topic , 这个topic有1个分区 , 3个副本</span></span><br><span class="line">bin/kafka-topics.sh --zookeeper 188.66.88.15:2181 --create --topic first --partitions 1 --replication-factor 3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除 topic</span></span><br><span class="line"><span class="comment"># 需要在server.properties中设置 delete.topic.enable=true 否则只是标记删除。</span></span><br><span class="line">bin/kafka-topics.sh --zookeeper 188.66.88.15:2181 --delete --topic first</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看某个 Topic 的详情</span></span><br><span class="line">bin/kafka-topics.sh --zookeeper 188.66.88.15:2181 --describe --topic first</span><br><span class="line"></span><br><span class="line"><span class="comment"># 发送消息(向Topic发送消息)</span></span><br><span class="line">bin/kafka-console-producer.sh --topic first --broker-list 188.66.88.15:2181</span><br><span class="line">&gt;hello world</span><br><span class="line">&gt;atguigu atguigu</span><br><span class="line"></span><br><span class="line"><span class="comment"># 消费消息</span></span><br><span class="line">bin/kafka-console-consumer.sh --zookeeper  188.66.88.15:2181 --topic first --from-beginning</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">bin/kafka-console-consumer.sh --bootstrap-server 188.66.88.15:9092 --topic first</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">bin/kafka-console-consumer.sh --bootstrap-server 188.66.88.15:9092 --from-beginning --topic first</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改分区数</span></span><br><span class="line">bin/kafka-topics.sh --zookeeper 188.66.88.15:2181 --alter --topic first --partitions 6</span><br></pre></td></tr></table></figure>

<ul>
<li><code>--topic</code>：定义 topic 名 </li>
<li><code>--replication-factor</code>：定义副本数 </li>
<li><code>--partitions</code>：定义分区数</li>
<li><code>--from-beginning</code>：会把主题中以往所有的数据都读取出来。</li>
</ul>
<h2 id="Demo：WordCount"><a href="#Demo：WordCount" class="headerlink" title="Demo：WordCount"></a>Demo：WordCount</h2><p>实现一个简单WordCount程序，它具备以下功能：</p>
<ol>
<li>支持词组持续输入，即生产者不断生成消息；</li>
<li>程序自动从输入Topic中获取原始数据，然后经过处理，将处理结果发布在计数Topic中；</li>
<li>消费者可以从计数Topic获取相应的WordCount的结果；</li>
</ol>
<h3 id="1-创建输入Topic"><a href="#1-创建输入Topic" class="headerlink" title="1. 创建输入Topic"></a>1. 创建输入Topic</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --zookeeper localhost:2181 --create --topic kafka-word-count-input --partitions 1 --replication-factor 1</span><br></pre></td></tr></table></figure>



<h3 id="2-向Topic输入消息"><a href="#2-向Topic输入消息" class="headerlink" title="2. 向Topic输入消息"></a>2. 向Topic输入消息</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-producer.sh --broker-list localhost:9092 --topic kafka-word-count-input</span><br></pre></td></tr></table></figure>



<h3 id="3-流处理逻辑"><a href="#3-流处理逻辑" class="headerlink" title="3. 流处理逻辑"></a>3. 流处理逻辑</h3><p>Java 8的版本:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCount</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(StreamsConfig.APPLICATION_ID_CONFIG, <span class="string">&quot;kafka-word-count&quot;</span>);</span><br><span class="line">        props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;localhost:9092&quot;</span>);</span><br><span class="line">        props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());</span><br><span class="line">        props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> StreamsBuilder builder = <span class="keyword">new</span> StreamsBuilder();</span><br><span class="line">        KStream&lt;String, String&gt; source = builder.&lt;String, String&gt;stream(<span class="string">&quot;kafka-word-count-input&quot;</span>);</span><br><span class="line">        Pattern pattern = Pattern.compile(<span class="string">&quot;\\W+&quot;</span>);</span><br><span class="line">        source</span><br><span class="line">           .flatMapValues(value -&gt; Arrays.asList(pattern.split(value.toLowerCase(Locale.getDefault()))))</span><br><span class="line">           .groupBy((key, value) -&gt; value)</span><br><span class="line">           .count(Materialized.&lt;String, Long, KeyValueStore&lt;Bytes, <span class="keyword">byte</span>[]&gt;&gt;as(<span class="string">&quot;counts-store&quot;</span>)).mapValues(value-&gt;Long.toString(value))</span><br><span class="line">           .toStream()</span><br><span class="line">           .to(<span class="string">&quot;kafka-word-count-output&quot;</span>);</span><br><span class="line">        <span class="keyword">final</span> KafkaStreams streams = <span class="keyword">new</span> KafkaStreams(builder.build(), props);</span><br><span class="line">        streams.start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Scala版本：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">WordCount</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    <span class="keyword">val</span> props: <span class="type">Properties</span> = &#123;</span><br><span class="line">      <span class="keyword">val</span> p = <span class="keyword">new</span> <span class="type">Properties</span>()</span><br><span class="line">      p.put(<span class="type">StreamsConfig</span>.<span class="type">APPLICATION_ID_CONFIG</span>, <span class="string">&quot;kafka-word-count&quot;</span>)</span><br><span class="line">      p.put(<span class="type">StreamsConfig</span>.<span class="type">BOOTSTRAP_SERVERS_CONFIG</span>, <span class="string">&quot;localhost:9092&quot;</span>)</span><br><span class="line">      p.put(<span class="type">StreamsConfig</span>.<span class="type">DEFAULT_KEY_SERDE_CLASS_CONFIG</span>, <span class="type">Serdes</span>.<span class="type">String</span>.getClass)</span><br><span class="line">      p.put(<span class="type">StreamsConfig</span>.<span class="type">DEFAULT_VALUE_SERDE_CLASS_CONFIG</span>, <span class="type">Serdes</span>.<span class="type">String</span>.getClass)</span><br><span class="line">      p</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> builder: <span class="type">StreamsBuilder</span> = <span class="keyword">new</span> <span class="type">StreamsBuilder</span>()</span><br><span class="line">    <span class="keyword">val</span> source: <span class="type">KStream</span>[<span class="type">String</span>, <span class="type">String</span>] = builder.stream(<span class="string">&quot;kafka-word-count-input&quot;</span>)</span><br><span class="line">    source</span><br><span class="line">      .flatMapValues(textLine =&gt; textLine.toLowerCase.split(<span class="string">&quot;\\W+&quot;</span>).toIterable.asJava)</span><br><span class="line">      .groupBy((_, word) =&gt; word)</span><br><span class="line">      .count(<span class="type">Materialized</span>.as[<span class="type">String</span>, <span class="type">Long</span>, <span class="type">KeyValueStore</span>[<span class="type">Bytes</span>, <span class="type">Array</span>[<span class="type">Byte</span>]]](<span class="string">&quot;counts-store&quot;</span>)).toStream.to(<span class="string">&quot;kafka-word-count-output&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> streams: <span class="type">KafkaStreams</span> = <span class="keyword">new</span> <span class="type">KafkaStreams</span>(builder.build(), props)</span><br><span class="line">    streams.start()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="4-启动处理逻辑"><a href="#4-启动处理逻辑" class="headerlink" title="4. 启动处理逻辑"></a>4. 启动处理逻辑</h3><p>这里演示的利用Maven构建的Java版本，具体执行步骤请参考<a target="_blank" rel="noopener" href="https://github.com/godpan/kafka-word-count">戳这里kafka-word-count</a>上的说明。</p>
<h3 id="5-启动消费者进程"><a href="#5-启动消费者进程" class="headerlink" title="5. 启动消费者进程"></a>5. 启动消费者进程</h3><p>最后我们启动消费者进程，并在生产者中输入一些单词，比如：</p>
<p><img src="/images/kafka-word-count-input.png" alt="kafka-word-count-input"></p>
<p>最后我们可以在消费者进程中看到以下输出：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --topic kafka-word-count-output --from-beginning --bootstrap-server localhost:9092  --property print.key=<span class="literal">true</span></span><br></pre></td></tr></table></figure>

<p><img src="/images/kafka-word-count-output.png" alt="kafka-word-count-output"></p>
<h1 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h1><ul>
<li><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1a4411B7V9">Kafka 教程 (消息队列 kafka 快速入门)</a></li>
<li><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV19A411t7kR">消息队列 kafka 一小时快速入门 2020 新版尝鲜！</a></li>
</ul>
</div></div></article><link rel="stylesheet" type="text/css" href="/css/font.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.css"><script src="//cdn.bootcss.com/jquery/2.0.3/jquery.min.js"></script><script src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js"></script><script>$(document).ready(function() {
  $(".fancybox").fancybox();
});
</script></body></html>