<!DOCTYPE html><html><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content=" id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;Kafka作为一个高吞吐的分布式的消息系统，目前已经被很多公司应用在实际的业务中了，并且与许多数据处理框架相结合，比如Hadoop，Spark等。"><link rel="stylesheet" type="text/css" href="/css/normalize.css"><link rel="stylesheet" type="text/css" href="/css/highlight.css"><link rel="stylesheet" type="text/css" href="/css/noise.css"><title>Kafka 学习笔记 | 凉薄的自动书记人偶</title><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><meta name="generator" content="Hexo 5.4.0"></head><body><article class="wrapper"><div class="post-main"><div class="nav"><nav class="container"><a class="sidebar-nav-item active" href="/">Home</a><a class="sidebar-nav-item" href="/archives">Tags</a><a class="sidebar-nav-item" href="/About">About</a></nav><div class="container post-meta"><div class="post-tags"><a class="post-tag-link" href="/tags/Kafka/" rel="tag">Kafka</a></div><div class="post-time">2021-08-06</div></div></div><div class="container post-header"><h1>Kafka 学习笔记</h1></div><div class="container post-toc"><details class="toc"><summary class="toc-accordion">Table of Contents</summary><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%83%8C%E6%99%AF"><span class="toc-number">1.</span> <span class="toc-text">背景</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F"><span class="toc-number">1.1.</span> <span class="toc-text">消息系统</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka"><span class="toc-number">2.</span> <span class="toc-text">Kafka</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Topics"><span class="toc-number">2.1.</span> <span class="toc-text">Topics</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Distribution"><span class="toc-number">2.2.</span> <span class="toc-text">Distribution</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Geo-Replication"><span class="toc-number">2.3.</span> <span class="toc-text">Geo-Replication</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Producers"><span class="toc-number">2.4.</span> <span class="toc-text">Producers</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Consumers"><span class="toc-number">2.5.</span> <span class="toc-text">Consumers</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Guarantees"><span class="toc-number">2.6.</span> <span class="toc-text">Guarantees</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Use"><span class="toc-number">3.</span> <span class="toc-text">Use</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka-as-a-Messaging-System"><span class="toc-number">3.1.</span> <span class="toc-text">Kafka as a Messaging System</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka-as-a-Storage-System"><span class="toc-number">3.2.</span> <span class="toc-text">Kafka as a Storage System</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka-for-Stream-Processing"><span class="toc-number">3.3.</span> <span class="toc-text">Kafka for Stream Processing</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E5%9C%A8Kafka%E4%B8%AD%E7%9A%84%E5%8E%86%E7%A8%8B"><span class="toc-number">4.</span> <span class="toc-text">消息在Kafka中的历程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C"><span class="toc-number">5.</span> <span class="toc-text">基础操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BD"><span class="toc-number">5.1.</span> <span class="toc-text">下载</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8"><span class="toc-number">5.2.</span> <span class="toc-text">启动</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BATopic"><span class="toc-number">5.3.</span> <span class="toc-text">创建Topic</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%91Topic%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF"><span class="toc-number">5.4.</span> <span class="toc-text">向Topic发送消息</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%8ETopic%E8%8E%B7%E5%8F%96%E6%B6%88%E6%81%AF"><span class="toc-number">5.5.</span> <span class="toc-text">从Topic获取消息</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#WordCount"><span class="toc-number">6.</span> <span class="toc-text">WordCount</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%90%AF%E5%8A%A8kafka"><span class="toc-number">6.1.</span> <span class="toc-text">1. 启动kafka</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%88%9B%E5%BB%BA%E8%BE%93%E5%85%A5Topic"><span class="toc-number">6.2.</span> <span class="toc-text">2. 创建输入Topic</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%90%91Topic%E8%BE%93%E5%85%A5%E6%B6%88%E6%81%AF"><span class="toc-number">6.3.</span> <span class="toc-text">3. 向Topic输入消息</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E6%B5%81%E5%A4%84%E7%90%86%E9%80%BB%E8%BE%91"><span class="toc-number">6.4.</span> <span class="toc-text">4. 流处理逻辑</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E5%90%AF%E5%8A%A8%E5%A4%84%E7%90%86%E9%80%BB%E8%BE%91"><span class="toc-number">6.5.</span> <span class="toc-text">5. 启动处理逻辑</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E5%90%AF%E5%8A%A8%E6%B6%88%E8%B4%B9%E8%80%85%E8%BF%9B%E7%A8%8B"><span class="toc-number">6.6.</span> <span class="toc-text">6. 启动消费者进程</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#kafka%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">7.</span> <span class="toc-text">kafka使用场景</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E6%81%AFMessaging"><span class="toc-number">7.1.</span> <span class="toc-text">消息Messaging</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E7%AB%99%E6%B4%BB%E5%8A%A8%E8%B7%9F%E8%B8%AA"><span class="toc-number">7.2.</span> <span class="toc-text">网站活动跟踪</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BA%A6%E9%87%8FMetrics"><span class="toc-number">7.3.</span> <span class="toc-text">度量Metrics</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%A5%E5%BF%97%E8%81%9A%E5%90%88"><span class="toc-number">7.4.</span> <span class="toc-text">日志聚合</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B5%81%E5%A4%84%E7%90%86"><span class="toc-number">7.5.</span> <span class="toc-text">流处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Event-Sourcing"><span class="toc-number">7.6.</span> <span class="toc-text">Event Sourcing</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8F%90%E4%BA%A4%E6%97%A5%E5%BF%97"><span class="toc-number">7.7.</span> <span class="toc-text">提交日志</span></a></li></ol></li></ol></details></div><div class="container post-content"><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>Kafka作为一个高吞吐的分布式的消息系统，目前已经被很多公司应用在实际的业务中了，并且与许多数据处理框架相结合，比如Hadoop，Spark等。</p>
<h3 id="消息系统"><a href="#消息系统" class="headerlink" title="消息系统"></a>消息系统</h3><p>在实际的业务需求中，我们需要处理各种各样的消息，比如Page View，日志，请求等，那么一个好的消息系统应该拥有哪些功能呢？</p>
<ul>
<li>拥有消息发布和订阅的功能，类似于消息队列或者企业消息传送系统；</li>
<li>能存储消息流，并具备容错性；</li>
<li>能够实时的处理消息；</li>
</ul>
<p>以上3点是作为一个好的消息系统的最基本的能力。</p>
<p>那么Kafka为什么会诞生呢？其实在我们工作中，相信有很多也接触过消息队列，甚至自己也写过简单的消息系统，它最基本应该拥有发布/订阅的功能，如下图所示：</p>
<p><img src="/images/simple-message-system.png" alt="simple-message-system"></p>
<p>其中消费者A与消费者B都订阅了消息源A和消息源B，这种模式很简单，但是相对来说也有弊端，比如以下两点：</p>
<ul>
<li>该模式下消费者需要实时去处理消息，因为这里消息源和消费者都不会维护一个消息队列（维护代价太大），这将会导致消费者若是暂时没有能力消费，则消息会丢失，当然也就不能获得历史的消息；</li>
<li>消息源需要维护原本不属于它的工作，比如维护订阅者（消费者）的信息，向多个消费者发送消息，亦或者有些还需要处理消息反馈，这是原本纯粹的消息源就会变得越来越复杂；</li>
</ul>
<p>当然这些问题都是可以改进的，比如我们可以在消息源和消费者中间增加一个消息队列，如下图所示：</p>
<p><img src="/images/simple-message-queue-system.png" alt="simple-message-queue-system"></p>
<p>从图中我们可以看出，现在消息源只需要将消息发送到消息队列中就行，至于其他就将给消息队列去完成，我们可以在消息队列持久化消息，主动推消息给已经订阅了该消息队列的消费者，那么这种模式还有什么缺点吗？</p>
<p>答案是有，上图只是两个消息队列，我们维护起来并不困难，但是如果有成百上千个呢？那不得gg，其实我们可以发现，消息队列的功能都很类似，无非就是持久化消息，推送消息，给出反馈等功能，结构也非常类似，主要是消息内容，当然如果要通用化，消息结构也要尽可能通用化，与具体平台具体语言无关，比如用JSON格式等，所有我们可以演变出以下的消息系统：</p>
<p><img src="/images/message-system.png" alt="message-system"></p>
<p>这个方式看起来只是把上面的队列合并到了一起，其实并不那么简单，因为这个消息队列集合要具备以下几个功能：</p>
<ul>
<li>能统一管理所有的消息队列，不是特殊需求不需要开发者自己去维护；</li>
<li>高效率的存储消息；</li>
<li>消费者能快速的找到想要消费的消息；</li>
</ul>
<p>当然这些只是最基本的功能，还有比如多节点容错，数据备份等，一个好的消息系统需要处理的东西非常多，很庆幸，Kafka帮我们做到了。</p>
<h2 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h2><p>在具体了解Kafka的细节前，我们先来看一下它的一些基本概念：</p>
<ul>
<li>Kafka是运行在一个集群上，所以它可以拥有一个或多个服务节点；</li>
<li>Kafka集群将消息存储在特定的文件中，<strong>对外表现为Topics</strong>；</li>
<li>每条消息记录都包含一个key，消息内容以及时间戳；</li>
</ul>
<p>从上面几点我们大致可以推测Kafka是一个分布式的消息存储系统，那么它就仅仅这么点功能吗，我们继续看下面。</p>
<p>Kafka为了拥有更强大的功能，提供了四大核心接口：</p>
<ul>
<li><code>Producer API</code>允许了应用可以向Kafka中的topics发布消息；</li>
<li><code>Consumer API</code>允许了应用可以订阅Kafka中的topics，并消费消息；</li>
<li><code>Streams API</code>允许应用可以作为消息流的处理者，比如可以<strong>从topicA中消费消息，处理的结果发布到topicB中</strong>；</li>
<li><code>Connector API</code>提供Kafka与现有的应用或系统适配功能，比如与数据库连接器可以捕获表结构的变化；</li>
</ul>
<p>它们与Kafka集群的关系可以用下图表示：</p>
<p><img src="/images/kafka-apis.png" alt="kafka-apis"></p>
<p>在了解了Kafka的一些基本概念后，我们具体来看看它的一些组成部分。</p>
<h3 id="Topics"><a href="#Topics" class="headerlink" title="Topics"></a>Topics</h3><p>顾名思义Topics是一些主题的集合，更通俗的说Topic就像一个消息队列，生产者可以向其写入消息，消费者可以从中读取消息，一个Topic支持多个生产者或消费者同时订阅它，所以其扩展性很好。Topic又可以由一个或多个partition（分区）组成，比如下图：</p>
<p><img src="/images/log-anatomy.png" alt="log-anatomy"></p>
<p>其中每个partition中的消息是有序的，但相互之间的顺序就不能保证了，若Topic有多个partition，生产者的消息可以指定或者由系统根据算法分配到指定分区，若你需要所有消息都是有序的，那么你最好只用一个分区。另外partition支持消息位移读取，消息位移有消费者自身管理，比如下图：</p>
<p><img src="/images/log-consumer.png" alt="log-consumer"></p>
<p>由上图可以看出，不同消费者对同一分区的消息读取互不干扰，消费者可以通过设置消息位移（offset）来控制自己想要获取的数据，比如可以从头读取，最新数据读取，重读读取等功能。</p>
<p>关于Topic的分区策略以及与消费者间平衡后续文章会继续深入讲解。</p>
<h3 id="Distribution"><a href="#Distribution" class="headerlink" title="Distribution"></a>Distribution</h3><p>上文说到过，Kafka是一个分布式的消息系统，所以当我们配置了多个Kafka Server节点后，它就拥有分布式的能力，比如容错等，<strong>partition会被分布在各个Server节点上</strong>，同时它们中间又有一个leader，它会处理所有的读写请求，其他followers会复制leader上的数据信息，一旦当leader因为某些故障而无法提供服务后，就会有一个follower被推举出来成为新的leader来处理这些请求。</p>
<h3 id="Geo-Replication"><a href="#Geo-Replication" class="headerlink" title="Geo-Replication"></a>Geo-Replication</h3><p>异地备份是作为主流分布式系统的基础功能，用于集群中数据的备份和恢复，Kafka利用MirrorMaker来实现这个功能，用户只需简单的进行相应配置即可。</p>
<h3 id="Producers"><a href="#Producers" class="headerlink" title="Producers"></a>Producers</h3><p>Producers作为消息的生产者，可以自己指定将消息发布到订阅Topic中的指定分区，策略可以自己指定，比如语义或者结构类似的消息发布在同一分区，当然也可以由系统循环发布在每一个分区上。</p>
<h3 id="Consumers"><a href="#Consumers" class="headerlink" title="Consumers"></a>Consumers</h3><p>Consumers是一群消费者的集合，可以称之为消费者组，是一种更高层次的的抽象，向Topic订阅消费消息的单位是Consumers，当然它其中也可以只有一个消费者（consumer）。下面是关于consumer的两条原则：</p>
<ul>
<li>假如所有消费者都在同一个消费者组中，那么它们将协同消费订阅Topic的部分消息（根据分区与消费者的数量分配），保存负载平衡；</li>
<li>假如所有消费者都在不同的消费者组中，并且订阅了同个Topic，那么它们将可以消费Topic的所有消息；</li>
</ul>
<p><img src="/images/consumer-groups.png" alt="consumer-groups"></p>
<p>上图中有两个Server节点，有一个Topic被分为四个分区（P0-P4)分别被分配在两个节点上，另外还有两个消费者组（GA，GB），其中GA有两个消费者实例，GB有四个消费者实例。</p>
<p>从图中我们可以看出，首先订阅Topic的单位是消费者组，另外我们发现Topic中的消息根据一定规则将消息推送给具体消费者，主要原则如下：</p>
<ul>
<li>若消费者数小于partition数，且消费者数为一个，那么它就消费所有消息；</li>
<li>若消费者数小于partition数，假设消费者数为N，partition数为M，那么每个消费者能消费的分区数为M/N或M/N+1；</li>
<li>若消费者数等于partition数，那么每个消费者都会均等分配到一个分区的消息；</li>
<li>若消费者数大于partition数，则将会出现部分消费者得不到消息分区，出现空闲的情况；</li>
</ul>
<p>总的来说，Kafka会根据消费者组的情况均衡分配消息，比如有消息着实例宕机，亦或者有新的消费者加入等情况。</p>
<h3 id="Guarantees"><a href="#Guarantees" class="headerlink" title="Guarantees"></a>Guarantees</h3><p>kafka作为一个高水准的系统，提供了以下的保证：</p>
<ul>
<li>消息的添加是有序的，生产者越早向订阅的Topic发送的消息，会更早的被添加到Topic中，当然它们可能被分配到不同的分区；</li>
<li>消费者在消费Topic分区中的消息时是有序的；</li>
<li>对于有N个复制节点的Topic，系统可以最多容忍N-1个节点发生故障，而不丢失任何提交给该Topic的消息丢失；</li>
</ul>
<h2 id="Use"><a href="#Use" class="headerlink" title="Use"></a>Use</h2><h3 id="Kafka-as-a-Messaging-System"><a href="#Kafka-as-a-Messaging-System" class="headerlink" title="Kafka as a Messaging System"></a>Kafka as a Messaging System</h3><p>Kafka相比其他的消息系统优势具体在哪里？传统的消息系统模型主要有两种：消息队列和发布/订阅。</p>
<ol>
<li>消息队列</li>
</ol>
<table>
<thead>
<tr>
<th align="left">特性</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="left">表现形式</td>
<td align="left">一组消费者从消息队列中获取消息，消息会被推送给组中的某一个消费者</td>
</tr>
<tr>
<td align="left">优势</td>
<td align="left">水平扩展，可以将消息数据分开处理</td>
</tr>
<tr>
<td align="left">劣势</td>
<td align="left">消息队列不是多用户的，当一条消息记录被一个进程读取后，消息便会丢失</td>
</tr>
</tbody></table>
<ol start="2">
<li>发布/订阅</li>
</ol>
<table>
<thead>
<tr>
<th align="left">特性</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="left">表现形式</td>
<td align="left">消息会广播发送给所有消费者</td>
</tr>
<tr>
<td align="left">优势</td>
<td align="left">可以多进程共享消息</td>
</tr>
<tr>
<td align="left">劣势</td>
<td align="left">每个消费者都会获得所有消息，无法通过添加消费进程提高处理效率</td>
</tr>
</tbody></table>
<p>从上面两个表中可以看出两种传统的消息系统模型的优缺点，所以Kafka在前人的肩膀上进行了优化，吸收他们的优点，主要体现在以下两方面：</p>
<ul>
<li>通过Topic方式来达到消息队列的功能</li>
<li>通过消费者组这种方式来达到发布/订阅的功能</li>
</ul>
<p>Kafka通过结合这两点（这两点的具体描述查看上面章节），完美的解决了它们两者模式的缺点。</p>
<h3 id="Kafka-as-a-Storage-System"><a href="#Kafka-as-a-Storage-System" class="headerlink" title="Kafka as a Storage System"></a>Kafka as a Storage System</h3><p>存储消息也是消息系统的一大功能，Kafka相对普通的消息队列存储来说，它的表现实在好的太多：</p>
<ul>
<li>Kafka支持<code>写入确认</code>，保证消息写入的正确性和连续性，</li>
<li>Kafka还会对写入磁盘的数据进行复制备份，来实现容错，</li>
<li>Kafka对磁盘的使用结构是一致的，就说说不管你的服务器目前磁盘存储的消息数据有多少，它添加消息数据的效率是相同的。</li>
</ul>
<p>Kafka的存储机制很好的支持消费者可以随意控制自身所需要读取的数据，在很多时候你也可以将Kafka作为一个高性能，低延迟的分布式文件系统。</p>
<h3 id="Kafka-for-Stream-Processing"><a href="#Kafka-for-Stream-Processing" class="headerlink" title="Kafka for Stream Processing"></a>Kafka for Stream Processing</h3><p>Kafka作为一个完美主义代表者，光有普通的读写，存储等功能是不够的，它还提供了<strong>实时处理消息流</strong>的接口。</p>
<p>很多时候原始的数据并不是我们想要的，我们想要的是经过处理后的数据结果，比如通过一天的搜索数据得出当天的搜索热点等，你可以利用Streams API来实现自己想要的功能，比如从输入Topic中获取数据，然后再发布到具体的输出Topic中。</p>
<p>Kafka的流处理可以解决诸如处理无序数据、数据的复杂转换等问题。</p>
<h2 id="消息在Kafka中的历程"><a href="#消息在Kafka中的历程" class="headerlink" title="消息在Kafka中的历程"></a>消息在Kafka中的历程</h2><p>我们可以先来看一下一条消息从发出到最后被消息者接收到底经历了什么</p>
<p><img src="/images/message-flow.png" alt="message-flow"></p>
<p>上图简要的说明了消息在Kafka中的整个流转过程（假设已经部署好了整个Kafka系统，并创建了相应的Topic，分区等细节后续再单独讲）：</p>
<ol>
<li>消息生产者将消息发布到具体的Topic，根据一定算法或者随机被分发到具体的partition中；</li>
<li>根据实际需求，是否需要实现处理消息逻辑；若需要，则实现具体逻辑后将结果发布到输出Topic；</li>
<li>消费者根据需求订阅相关Topic，并消费消息；</li>
</ol>
<p>总的来说，流程还是比较清晰和简单的，下面就练习Kafka的基本操作，最后实现一个单词计数的小demo。</p>
<h2 id="基础操作"><a href="#基础操作" class="headerlink" title="基础操作"></a>基础操作</h2><p>以下代码及相应测试在以下环境测试通过：Mac OS + JDK1.8，Linux系统应该也能跑通，Windows有兴趣的同学可以去官网下载相应版本进行相应的测试练习。</p>
<h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><p>Mac系统同学可以使用brew安装：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install kafka</span><br></pre></td></tr></table></figure>

<p>Linux系统同学可以从官网下载源码解压，也可以直接执行以下命令:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> </span><br><span class="line">mkdir test-kafka &amp;&amp; <span class="built_in">cd</span> test-kafka</span><br><span class="line">curl -o kafka_2.11-1.0.1.tgz http://mirrors.tuna.tsinghua.edu.cn/apache/kafka/1.0.1/kafka_2.11-1.0.1.tgz</span><br><span class="line">tar -xzf kafka_2.11-1.0.1.tgz</span><br><span class="line"><span class="built_in">cd</span> kafka_2.11-1.0.1</span><br></pre></td></tr></table></figure>



<h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><p>Kafka使用Zookeeper来维护集群信息，所以这里我们先要启动Zookeeper，Kafka与Zookeeper的相关联系跟结合后续再深入了解。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/zookeeper-server-start.sh config/zookeeper.properties</span><br></pre></td></tr></table></figure>

<p>接着我们启动一个Kafka Server节点：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-server-start.sh config/server.properties</span><br></pre></td></tr></table></figure>

<p>这时候Kafka系统已经算是启动起来了。</p>
<h3 id="创建Topic"><a href="#创建Topic" class="headerlink" title="创建Topic"></a>创建Topic</h3><p>在一切就绪之后，我们要开始做极其重要的一步，那就是创建Topic，Topic是整个系统流转的核心，另外Topic本身也包含着很多复杂的参数，比如复制因子个数，分区个数等，这里为了从简，我们将对应的参数都设为1，方便大家测试：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic kakfa-test</span><br></pre></td></tr></table></figure>

<p>其中参数的具体含义：</p>
<table>
<thead>
<tr>
<th align="left">属性</th>
<th align="left">功能</th>
</tr>
</thead>
<tbody><tr>
<td align="left">–create</td>
<td align="left">代表创建Topic</td>
</tr>
<tr>
<td align="left">–zookeeper</td>
<td align="left">zookeeper集群信息</td>
</tr>
<tr>
<td align="left">–replication-factor</td>
<td align="left">复制因子</td>
</tr>
<tr>
<td align="left">–partitions</td>
<td align="left">分区信息</td>
</tr>
<tr>
<td align="left">–topic</td>
<td align="left">Topic名称</td>
</tr>
</tbody></table>
<p>这时候我们已经创建好了一个叫kakfa-test的Topic了。</p>
<h3 id="向Topic发送消息"><a href="#向Topic发送消息" class="headerlink" title="向Topic发送消息"></a>向Topic发送消息</h3><p>在有了Topic后我们就可以向其发送消息：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-producer.sh --broker-list localhost:9092 --topic kakfa-test</span><br></pre></td></tr></table></figure>

<p>然后我们向控制台输入一些消息：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">this is my first test kafka</span><br><span class="line">so good</span><br></pre></td></tr></table></figure>

<p>这时候消息已经被发布在kakfa-test这个主题上了。</p>
<h3 id="从Topic获取消息"><a href="#从Topic获取消息" class="headerlink" title="从Topic获取消息"></a>从Topic获取消息</h3><p>现在Topic上已经有消息了，现在可以从中获取消息被消费：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic kafka-test --from-beginning</span><br></pre></td></tr></table></figure>

<p>这时候我们可以在控制台看到：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">this is my first <span class="built_in">test</span> kafka</span><br><span class="line">so good</span><br></pre></td></tr></table></figure>

<p>至此我们就测试了最简单的Kafka Demo，希望大家能自己动手去试试，虽然很简单，但是这能让你对整个Kafka流程能更熟悉。</p>
<h2 id="WordCount"><a href="#WordCount" class="headerlink" title="WordCount"></a>WordCount</h2><p>下面我们来利用上面的一些基本操作来实现一个简单WordCount程序，它具备以下功能：</p>
<ol>
<li>支持词组持续输入，即生产者不断生成消息；</li>
<li>程序自动从输入Topic中获取原始数据，然后经过处理，将处理结果发布在计数Topic中；</li>
<li>消费者可以从计数Topic获取相应的WordCount的结果；</li>
</ol>
<h3 id="1-启动kafka"><a href="#1-启动kafka" class="headerlink" title="1. 启动kafka"></a>1. 启动kafka</h3><p>与上文的启动一样，按照其操作即可。</p>
<h3 id="2-创建输入Topic"><a href="#2-创建输入Topic" class="headerlink" title="2. 创建输入Topic"></a>2. 创建输入Topic</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --zookeeper localhost:2181 --create --topic kafka-word-count-input --partitions 1 --replication-factor 1</span><br></pre></td></tr></table></figure>



<h3 id="3-向Topic输入消息"><a href="#3-向Topic输入消息" class="headerlink" title="3. 向Topic输入消息"></a>3. 向Topic输入消息</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-producer.sh --broker-list localhost:9092 --topic kafka-word-count-input</span><br></pre></td></tr></table></figure>



<h3 id="4-流处理逻辑"><a href="#4-流处理逻辑" class="headerlink" title="4. 流处理逻辑"></a>4. 流处理逻辑</h3><p>这部分内容是整个例子的核心，这部分代码有Java 8+和Scala版本，个人认为流处理用函数式语法表达的更加简洁清晰，推荐大家用函数式的思维去尝试写以下。</p>
<p>我们先来看一个Java 8的版本:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCount</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(StreamsConfig.APPLICATION_ID_CONFIG, <span class="string">&quot;kafka-word-count&quot;</span>);</span><br><span class="line">        props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;localhost:9092&quot;</span>);</span><br><span class="line">        props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());</span><br><span class="line">        props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> StreamsBuilder builder = <span class="keyword">new</span> StreamsBuilder();</span><br><span class="line">        KStream&lt;String, String&gt; source = builder.&lt;String, String&gt;stream(<span class="string">&quot;kafka-word-count-input&quot;</span>);</span><br><span class="line">        Pattern pattern = Pattern.compile(<span class="string">&quot;\\W+&quot;</span>);</span><br><span class="line">        source</span><br><span class="line">           .flatMapValues(value -&gt; Arrays.asList(pattern.split(value.toLowerCase(Locale.getDefault()))))</span><br><span class="line">           .groupBy((key, value) -&gt; value)</span><br><span class="line">           .count(Materialized.&lt;String, Long, KeyValueStore&lt;Bytes, <span class="keyword">byte</span>[]&gt;&gt;as(<span class="string">&quot;counts-store&quot;</span>)).mapValues(value-&gt;Long.toString(value))</span><br><span class="line">           .toStream()</span><br><span class="line">           .to(<span class="string">&quot;kafka-word-count-output&quot;</span>);</span><br><span class="line">        <span class="keyword">final</span> KafkaStreams streams = <span class="keyword">new</span> KafkaStreams(builder.build(), props);</span><br><span class="line">        streams.start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>是不是很惊讶，用java也能写出如此简洁的代码，所以说如果有适用场景，推荐大家尝试的用函数式的思维去写写java代码。</p>
<p>我们再来看看Scala版本的：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">WordCount</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    <span class="keyword">val</span> props: <span class="type">Properties</span> = &#123;</span><br><span class="line">      <span class="keyword">val</span> p = <span class="keyword">new</span> <span class="type">Properties</span>()</span><br><span class="line">      p.put(<span class="type">StreamsConfig</span>.<span class="type">APPLICATION_ID_CONFIG</span>, <span class="string">&quot;kafka-word-count&quot;</span>)</span><br><span class="line">      p.put(<span class="type">StreamsConfig</span>.<span class="type">BOOTSTRAP_SERVERS_CONFIG</span>, <span class="string">&quot;localhost:9092&quot;</span>)</span><br><span class="line">      p.put(<span class="type">StreamsConfig</span>.<span class="type">DEFAULT_KEY_SERDE_CLASS_CONFIG</span>, <span class="type">Serdes</span>.<span class="type">String</span>.getClass)</span><br><span class="line">      p.put(<span class="type">StreamsConfig</span>.<span class="type">DEFAULT_VALUE_SERDE_CLASS_CONFIG</span>, <span class="type">Serdes</span>.<span class="type">String</span>.getClass)</span><br><span class="line">      p</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> builder: <span class="type">StreamsBuilder</span> = <span class="keyword">new</span> <span class="type">StreamsBuilder</span>()</span><br><span class="line">    <span class="keyword">val</span> source: <span class="type">KStream</span>[<span class="type">String</span>, <span class="type">String</span>] = builder.stream(<span class="string">&quot;kafka-word-count-input&quot;</span>)</span><br><span class="line">    source</span><br><span class="line">      .flatMapValues(textLine =&gt; textLine.toLowerCase.split(<span class="string">&quot;\\W+&quot;</span>).toIterable.asJava)</span><br><span class="line">      .groupBy((_, word) =&gt; word)</span><br><span class="line">      .count(<span class="type">Materialized</span>.as[<span class="type">String</span>, <span class="type">Long</span>, <span class="type">KeyValueStore</span>[<span class="type">Bytes</span>, <span class="type">Array</span>[<span class="type">Byte</span>]]](<span class="string">&quot;counts-store&quot;</span>)).toStream.to(<span class="string">&quot;kafka-word-count-output&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> streams: <span class="type">KafkaStreams</span> = <span class="keyword">new</span> <span class="type">KafkaStreams</span>(builder.build(), props)</span><br><span class="line">    streams.start()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以发现使用Java 8函数式风格编写的代码已经跟Scala很相似了。</p>
<h3 id="5-启动处理逻辑"><a href="#5-启动处理逻辑" class="headerlink" title="5. 启动处理逻辑"></a>5. 启动处理逻辑</h3><p>很多同学电脑上并没有装sbt，所以这里演示的利用Maven构建的Java版本，具体执行步骤请参考<a target="_blank" rel="noopener" href="https://github.com/godpan/kafka-word-count">戳这里kafka-word-count</a>上的说明。</p>
<h3 id="6-启动消费者进程"><a href="#6-启动消费者进程" class="headerlink" title="6. 启动消费者进程"></a>6. 启动消费者进程</h3><p>最后我们启动消费者进程，并在生产者中输入一些单词，比如：</p>
<p><img src="/images/kafka-word-count-input.png" alt="kafka-word-count-input"></p>
<p>最后我们可以在消费者进程中看到以下输出：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --topic kafka-word-count-output --from-beginning --bootstrap-server localhost:9092  --property print.key=<span class="literal">true</span></span><br></pre></td></tr></table></figure>

<p><img src="/images/kafka-word-count-output.png" alt="kafka-word-count-output"></p>
<h2 id="kafka使用场景"><a href="#kafka使用场景" class="headerlink" title="kafka使用场景"></a>kafka使用场景</h2><h3 id="消息Messaging"><a href="#消息Messaging" class="headerlink" title="消息Messaging"></a>消息Messaging</h3><ul>
<li><strong>Kafka可以替代更传统的消息代理</strong>。消息代理的使用有多种原因（将处理与数据生成器分离，缓冲未处理的消息等）。</li>
<li><strong>与大多数消息传递系统相比，Kafka具有更好的吞吐量，内置分区，复制和容错功能</strong>，这使其成为大规模消息处理应用程序的理想解决方案。</li>
<li>根据经验，消息传递的使用通常相对较低，但可能需要较低的端到端延迟，并且通常取决于Kafka提供的强大的耐用性保证。</li>
<li>在这个领域，Kafka可与传统的消息传递系统（如<a target="_blank" rel="noopener" href="http://activemq.apache.org/">ActiveMQ</a>或 <a target="_blank" rel="noopener" href="https://www.rabbitmq.com/">RabbitMQ</a>）相媲美。</li>
</ul>
<h3 id="网站活动跟踪"><a href="#网站活动跟踪" class="headerlink" title="网站活动跟踪"></a>网站活动跟踪</h3><ul>
<li>Kafka的原始用例是能够将用户活动跟踪管道重建为一组实时发布 - 订阅源。这意味着站点活动（页面查看，搜索或用户可能采取的其他操作）将发布到中心主题，每个活动类型包含一个主题。这些源可用于订购一系列用例，<strong>包括实时处理，实时监控以及加载到Hadoop或离线数据仓库系统以进行脱机处理和报告</strong>。</li>
<li>活动跟踪通常非常高，因为为每个用户页面视图生成了许多活动消息。</li>
</ul>
<h3 id="度量Metrics"><a href="#度量Metrics" class="headerlink" title="度量Metrics"></a>度量Metrics</h3><p><strong>Kafka通常用于运营监控数据</strong>。这涉及从分布式应用程序聚合统计信息以生成操作数据的集中式提要。</p>
<h3 id="日志聚合"><a href="#日志聚合" class="headerlink" title="日志聚合"></a>日志聚合</h3><ul>
<li>许多人使用Kafka作为日志聚合解决方案的替代品。</li>
<li>日志聚合通常从服务器收集物理日志文件，并将它们放在中央位置（可能是文件服务器或HDFS）进行处理。<strong>Kafka抽象出文件的细节，并将日志或事件数据作为消息流更清晰地抽象出来</strong>。这允许更低延迟的处理并更容易支持多个数据源和分布式数据消耗。</li>
<li>与Scribe或Flume等以日志为中心的系统相比，<strong>Kafka提供了同样出色的性能，由于复制而具有更强的耐用性保证，以及更低的端到端延迟。</strong></li>
</ul>
<h3 id="流处理"><a href="#流处理" class="headerlink" title="流处理"></a>流处理</h3><ul>
<li>许多Kafka用户在处理由多个阶段组成的管道时处理数据，<strong>其中原始输入数据从Kafka主题中消费，然后聚合，丰富或以其他方式转换为新主题以供进一步消费或后续处理</strong>。</li>
<li>例如，用于推荐新闻文章的处理管道可以从RSS订阅源抓取文章内容并将其发布到“文章”主题; 进一步处理可能会对此内容进行规范化或重复数据删除，并将已清理的文章内容发布到新主题; 最终处理阶段可能会尝试向用户推荐此内容。此类处理管道基于各个主题创建实时数据流的图形。从0.10.0.0开始，这是一个轻量级但功能强大的流处理库，名为<a target="_blank" rel="noopener" href="http://kafka.apache.org/documentation/streams">Kafka Streams</a> 在Apache Kafka中可用于执行如上所述的此类数据处理。</li>
<li>除了Kafka Streams之外，其他开源流处理工具包括<a target="_blank" rel="noopener" href="https://storm.apache.org/">Apache Storm</a>和 <a target="_blank" rel="noopener" href="http://samza.apache.org/">Apache Samza</a>。</li>
</ul>
<h3 id="Event-Sourcing"><a href="#Event-Sourcing" class="headerlink" title="Event Sourcing"></a>Event Sourcing</h3><p>Event Sourcing是一种应用程序设计风格，其中状态更改记录为按时间排序的记录序列。Kafka对非常大的存储日志数据的支持使其成为以这种风格构建的应用程序的出色后端。</p>
<h3 id="提交日志"><a href="#提交日志" class="headerlink" title="提交日志"></a>提交日志</h3><p><strong>Kafka可以作为分布式系统的一种外部提交日志</strong>。该日志有助于在节点之间复制数据，并充当故障节点恢复其数据的重新同步机制。Kafka中的日志压缩功能有助于支持此用法。在这种用法中，Kafka类似于<a target="_blank" rel="noopener" href="https://bookkeeper.apache.org/">Apache BookKeeper</a>项目。</p>
</div></div></article><link rel="stylesheet" type="text/css" href="/css/font.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.css"><script src="//cdn.bootcss.com/jquery/2.0.3/jquery.min.js"></script><script src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js"></script><script>$(document).ready(function() {
  $(".fancybox").fancybox();
});
</script></body></html>